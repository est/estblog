<!DOCTYPE html>
<html>
  <head>
<link rel="icon" href="https://est.im/favicon.svg">    <title>est の 输入 输出和出入</title>

    <meta charset="utf-8" />
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta http-equiv="Content-Security-Policy" content="frame-ancestors 'self' https://disqus.com https://player.bilibili.com https://www.youtube.com;">
    <link href="https://feeds.feedburner.com/initiative" type="application/rss+xml" rel="alternate" title="est の 输入 输出和出入 RSS Feed" />

    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="This blog is rated 🔞, viewer discretion is advised" />

    <meta property="og:url" content="https://blog.est.im">
    <meta property="og:type" content="website">
    <meta property="og:title" content="est の 输入 输出和出入">
    <meta property="og:description" content="This blog is rated 🔞, viewer discretion is advised">

    <link rel="stylesheet" href="/theme/css/normalize.min.css" />
    <link rel="stylesheet" href="/theme/css/style.css" />


    <style>
      body {
        background: #ecedef url("/theme/img/ignasi_pattern_s.png") repeat;
      }
    </style>
  </head>
  <body class="list-body">
<nav class="nav-bar side-padding">
  <h1 class="nav-header"><a href="/" class="nav-text">
    est の 输入 输出和出入
  </a></h1>
  <div class="hamburger-menu">
    <button>
      <span></span>
      <span></span>
    </button>
    <ul id="menu" class="hamburger-menu-overlay">
      <li><a href="/" class="hamburger-menu-overlay-link">Home</a></li>
      <li><a href="https://feeds.feedburner.com/initiative" class="hamburger-menu-overlay-link">RSS</a></li>
      <li><a href="/about" class="hamburger-menu-overlay-link">About</a></li>
      <li><a href="/category" class="hamburger-menu-overlay-link">Category</a></li>

    </ul>
  </div>
</nav>    <main class="card-container side-gutter">
      <header class="list-header">
        <p class="list-header-subtext">This blog is rated 🔞, viewer discretion is advised</p>
        <!-- <h1 class="list-header-title">est の 输入 输出和出入</h1> -->
      </header>


        <!-- new article -->
        <div class="card blog-card">
          <article class="card-body">
            <a href="/2026/stdin-04"  rel="bookmark" >
              <h2 class="card-title">观星有感</h2>
            </a>
            <p class="card-text"><p>这几天在乡下，看着漫天的星星，很多事情通过AI 得到了快速解答。于是记录一下</p>
<h2>观星</h2>
<p>肉眼能看到的星星，100%来自银河系。</p>
<p>同样的问题问娃，它们猜可能50%来自银河系。我个人之前估计是 80%哈哈哈。结果都错了。</p>
<p>如果你裸眼视力惊人，而且专业，那么在北半球能看到离我们最近的 仙女座星系（M31）的模糊光斑，在南半球能看到云雾状的大/小麦哲伦云。</p>
<p>肉眼能看到的星星，只占银河系的 0.0010% 左右。约6000颗（视星等 ≤ 6），银河系一共约 1000亿–4000亿颗</p>
<p>这6000颗星星，从生命周期的时间比例来看，确实大多数都是快燃尽的“老年”恒星</p>
<p>宇宙中90%以上的恒星都是像太阳一样正处于“青壮年”期的主序星，但是这些绝大多数的主序星又太暗了。</p>
<p>寿命最长的，占比最多的 红矮星 完全不可见；寿命最短的 蓝超巨星 最容易看见；演化晚期巨星，寿命短但光度暴增，是肉眼可见样本中的主力。</p>
<h2>AI没有世界观</h2>
<p>提了个问题：</p>
<p>为啥无论恒星多大多亮多远看起来都差不多大差不多亮？</p>
<p>不同的AI回答大同小异，上来就一堆定义，点光源，角分，角秒，距离，星等，视星等，大气吸收，虽然我能看懂，但是给娃讲完全没了兴趣。</p>
<p>我个人觉得吧，这其实不是天文和物理问题，不大不亮太远的的看不见，哈哈哈哈，选择偏差 (seletion bias)。AI表示你说得对。这才是为什么的终极原因。</p>
<p>然后我又问AI，为啥就没有零星的几个 巨大，或者巨亮的星星在夜空？</p>
<p>AI 又是一顿分析，天文单位AU距离，恒星的形成，质量比例，寿命，演化过程等等。</p>
<p>我说，如果真有一颗星星大得多，亮的多，恐怕要担心太阳系的安全性了，或者超新星爆发，当心伽马射线爆了。这也是一种幸存者偏差。也就是说如果有个文明能看到日月之外还有巨大巨亮的星星，那么这个文明被天体摧毁的可能性更大。</p>
<p>我感觉AI有一种苏式教材的美，不管3721，先给你一堵墙的知识，一顿灌输，你学了就完了。至于里面最重要的脉络关键，你就自个儿琢磨去吧。一唔一个不吱声。</p>
<p>总之，肉眼能看见的星星，几乎都是高等级的。能量大，个头大，离得近，缺一不可</p>
<h2>星空的延迟</h2>
<p>因为光年的缘故，太阳是我们看到最“实时”的星星，大概8分钟。其他 肉眼能看到的银河系恒星大概处于一个什么样的“延迟” 水平？</p>
<p>问了AI，银河里肉眼能看到的恒星，大多数集中在几百光年到几千光年之间。AI给了我一个分布，延迟在4.3-200年以内的大概35%，一千年以内的大概50%。你能看到汉唐甚至更老的星星占15%</p>
<h2>点亮夜空</h2>
<p>又想到个问题，现阶段，能点燃的星星都基本差不多被点燃了呢，还是说才刚刚开始，还是说不好说？</p>
<p>宇宙的恒星形成已经过了黄金时代，正在缓慢熄火，但远未结束——可以说高潮已过，余烬尚温。</p>
<p>然后又从AI那里学到了 Population I，Population II，以及太阳这种 Population III。我又问</p>
<p>星云所谓的“尘埃”是我们生活中接触的“尘埃”吗？隔两米远看见尘埃都费劲，望远镜看系外行星都费劲，还能看见其他星系的“尘埃”？？搞笑呢</p>
<p>发现我“星尘”的理解太字面了平凡了。带电，总质量大、能量高，高速流动，有激波和涡旋、波动和磁场作用，能被附近恒星加热产生热辐射的“灰烬”</p>
<p>氢氦 “灰烬” 形成Population I，第一代恒星自爆燃尽，混合其他元素形成 II, III</p>
<p>太阳系或者更近的地方没这种星云，是因为天体清扫轨道，加上太阳风。也就是说，初期宇宙，到处都是灰。</p>
<h2>旋臂是一种密度波</h2>
<p>这个也是让我吃惊的一个发现。一直以为银河系那个 旋臂 就是一直转起来拖拽形成的，后来才知道它就是各个恒星围绕银河系质心做椭圆运动，旋臂上的星星看上去比较密而已。</p>
<p>分别让几个AI搓了个网页demo，目前看起来 gemini 是最聪明的。</p>
<ul>
<li><a href="https://lab.est.im/galactic_spiral/deepseek.html">deepseek</a></li>
<li><a href="https://lab.est.im/galactic_spiral/qwen.html">qwen</a></li>
<li><a href="https://lab.est.im/galactic_spiral/chatgpt.html">chatgpt</a></li>
<li><a href="https://lab.est.im/galactic_spiral/gemini3.html">gemini3</a></li>
<li><a href="https://lab.est.im/galactic_spiral/grok.html">grok</a></li>
</ul>
<h2>银河系质心是什么</h2>
<p>有人说 <code>Sgr A*</code> 是个超级大黑洞，而且算出来质量是 430万个太阳。但是黑洞的引力主导范围叫希尔球（Hill Sphere）或影响半径，算下来 <code>Sgr A*</code> 仅能拽动约 3–10 光年内的恒星。银河系半径：约 50,000 光年，</p>
<p>也就是说，那颗黑洞质量仅占银河系总质量的约 0.0007%——就算把它拿掉，银河系旋转曲线几乎不变。学术上只能拿出「暗物质」来搪塞。</p>
<p>黑洞是个反直觉的东西，你以为它能吞噬一切，实际上它就像一口水井，只要你不直接踩空，但凡你稍微绕路一点，那么你多半掉不进去。</p>
<p>所以银河系中心是个啥呢？或许就是个质心。不是一个巨大的单一实体引力源？</p>
<hr />
<p>有AI还是挺方便的。以前要读很多wikipedia连蒙带猜，现在多问几轮就有比较好的理解了。</p></p>
            <div class="card-subtext muted-text">
              <p>Posted <time datetime="2026-02-24T10:10:00+08:00">2026-02-24</time></p>
<p>Stdin</p>            </div>
          </article>
        </div>


        <!-- new article -->
        <div class="card blog-card">
          <article class="card-body">
            <a href="/2026/stdin-03"  rel="bookmark" >
              <h2 class="card-title">体细胞阶级论——当繁衍权被剥夺</h2>
            </a>
            <p class="card-text"><p>最近关于AI对社会对冲击有很多讨论，比如 <a href="https://v2ex.com/t/1193282?">AI 能力大幅提升后，我们大部分人是不是躺平就可以了？</a>。很多大佬比如 Elon Musk 也说AGI之后，会有UBI</p>
<p>前段时间甚至看到个毫不相关的，<a href="https://www.zhihu.com/pin/2004648482347171867">智能机的普及和生育率降低有相关性</a>，提出一个惊世骇俗的观点，不婚不育，女权问题，可能要怪雷军？哈哈哈</p>
<p>基于这两个设定：</p>
<ol>
<li>因为生育率降低，大部分人可能以后要绝育，不能繁衍</li>
<li>大部分人能吃到AI给的低保</li>
</ol>
<p>我们尝试做一个思想实验：</p>
<p><strong>人作为一个个体，就如同单个细胞；社会作为整体，比如一个国家，变成一个「多细胞」生命体</strong></p>
<p>UBI这廉价的碳水，不就是ATP直接供给每个细胞么。这个设定其实挺老生常谈了。我感兴趣的是，单个细胞的一生就如同人的一生，细胞和细胞有差别，那么做<strong>哪一种</strong>细胞最划算？</p>
<p>由于本人生物知识已经还给高中老师了，千禧年之后生物科学又有很大颠覆性进步，所以就跟AI几轮辩经，得出一些结论，仅供参考。</p>
<h3>多细胞的好处</h3>
<p>首先，单细胞如果没有环境压力和竞争，那么可以活得很久的。但是周边上强度之后，多细胞作为整体，是要强过单打独斗的单细胞的。一种单细胞很容易被另一种克制它的单细胞团灭，生命甚至只有几个小时。所以单细胞几乎把所有的资源和精力都投放在繁殖上了。</p>
<h3>多细胞的代价</h3>
<p>多细胞模式，意味着部分细胞，必然放弃繁衍权</p>
<p>在生物学上，这玩意有个专属名词「魏斯曼屏障 Weismann Barrier」，生殖细胞叫 Germline，不能的叫体细胞 somatic cell</p>
<p>大部分细胞理论上也能恢复生殖能力，但是被DNA和激素抑制了的。日本人 山中 Yamanaka 在2006年发明了 诱导多能干细胞技术（iPS 技术），通过OSKM四个转录因子让体细胞也能繁殖。</p>
<p>这玩意我上学的时候没有 😵  当然强行改命极有可能会导致癌症。</p>
<p>癌症就是不受控制的繁殖。</p>
<h3>股东细胞</h3>
<p>生命体身上只有一种股东细胞，那就是负责繁衍的 生殖细胞。</p>
<p>AI告诉我，生殖细胞是唯一不参与“凋亡协议”的细胞。寿命长，几乎和生命体同寿。还包吃包住，衣食无忧，不用干活。大部分动物对生殖器官保护和供给都是级别很高。</p>
<p>对应到人类社会，你要繁衍权，必须运气好，长得帅和健康。</p>
<p>听上去挺不错？我仔细跟AI问清楚了，这玩意分雌性和雄性，其实命运也不太好，主要有个抽卡机制的问题</p>
<h4>精原干细胞</h4>
<p>寿命：理论永生（有坑）<br />
居住：35℃ 恒温地堡<br />
安全：专门的特勤安保，免疫系统豁免。因为精子本身会有排异反应<br />
供养：精选特供<br />
行动：坐牢<br />
工作：不用付出劳动。专心复制DNA准备繁衍<br />
日常：吃饭打牌睡觉<br />
陪从：支持细胞/Sertoli Cells。给你准备牌桌，和检查是否出老千</p>
<p>听上去是个绝佳的理想细胞岗位啊。那么代价呢？</p>
<p>设想你是一个无忧无虑的精原干细胞，这种细胞从生下来开始就每天吃饭打牌睡觉，但是打牌其实是一种俄罗斯轮盘赌。你赢了，第二天继续吃饭打牌睡觉；但凡你输了，那么恭喜你，你的生命进入倒计时，接下来你必须在几小时准备去“吉哈德”：</p>
<ul>
<li>把90%的细胞质打包成“残余体”扔掉。不需要修车厂（内质网），不需要发电站（大部分线粒体只留几根），不需要仓库（脂滴全扔）。</li>
<li>你只需要一个流线型外壳 + 一根鞭子 + 一包DNA。</li>
<li>扔掉修复系统。核切除修复？关停。抗氧化酶？绝大部分放弃。凋亡程序？保留，只用于“游不动就自杀”。</li>
<li>精子进入雌性生殖道后，代谢底物完全依赖外源（果糖、乳酸）。它自己没有任何储备。你开着一辆没油箱的车，烧的是路上的汽油——烧完就停。</li>
</ul>
<p>拆掉所有多余的系统，只带一包核弹头（基因组），冲进赛道，99.99%在几小时内解体，剩下的0.01%撞上卵子，阿拉呼阿克巴，把自己炸成碎片，把核弹头送进去，使命完成。</p>
<h4>卵细胞</h4>
<p>寿命：理论永生（有坑）<br />
入岗：生下来完成排岗。卵子的数量是固定的，只会越来越少<br />
居住：37°C 豪华总统套房<br />
起居：专门的颗粒细胞（Granulosa Cells）佣人负责伙食，心里按摩，打扫<br />
行动：坐牢<br />
工作：第一次减数分裂前期完成之后，啥都不用干<br />
日常：0-12岁就纯玩。12岁开始到50岁，每到经期选中一个幸运儿出去，作为靶子立正挨枪毙。</p>
<p>值得注意的是，绝经之后，豪华总统套房会突然收到强拆通知，几十万颗卵子一夜之间被集体坑杀殉葬。卵巢原地变公墓，被成纤维细胞带来的胶原蛋白给活埋了</p>
<p>那个曾经孕育无限可能的生命起源地，会变成一坨坚硬、发白、毫无生机的‘肉’——那是集体公墓，学术上叫结缔组织，社会上叫 过气资产的废墟。</p>
<p>呃，你说这不公平啊，要反抗？那么结局就是——妇科病 😂</p>
<h3>边角料和耗材</h3>
<p>表皮角质细胞 (Skin Keratinocytes) / 肠吸收细胞 (Intestinal Absorptive Cells)</p>
<p>组织和机构里内部孵化，就活几天，直接对抗物理磨损、酸碱与粪便。暴露的边境前线，吃的是系统残渣。脱落就死亡gg</p>
<h3>腺体系统</h3>
<ul>
<li>胰岛B细胞：中央银行行长/精算师。24小时盯着血糖指数，差0.01%都得发公告（激素）。吃住都在胰岛银行办公楼，安保极严。能源一级配给，不缺预算</li>
<li>垂体细胞：“发改委”。告诉甲状腺该搞建设，告诉生殖腺该备孕。颅底核心地带，离皇宫（大脑）最近。顶级安保，生活极度规律。</li>
<li>杯状细胞：物业公司/环卫局，提供润滑与屏障。 每天不停吐粘液，防止帝国边境生锈。湿冷的肠道/呼吸道边缘，环境略脏。吃点大家剩下的，日子还行。</li>
<li>汗腺/唾液腺细胞：市政公共服务 散热与预处理。虽然辛苦，但地位比较稳定，但工作环境受外界波动大。</li>
</ul>
<h3>央办+文娱传媒</h3>
<p>我写过一篇《<a href="https://blog.est.im/2022/stderr-05">戏子和故事</a>》，其实所谓的王权，甚至神权，就是一种讲故事的能力。所以中央政府，文娱传媒实际上是穿一条裤子的。央办做到极致，干脆就只负责意识形态——也就是网信和广电算了。三哥的“婆罗门”阶级就是干这个的。只负责讲故事和祭祀。</p>
<p>神经元细胞。胚胎期锁死，绝无扩招。终身制铁饭碗，高规格安防中心（血脑屏障），戒备森严。顶级财政拨款（20%能量），饿谁不能饿领导。寿命百年（与宿主同寿）。死一个少一个，不可替代。全身八卦都可以第一时间得知。</p>
<p>但24小时全天待岗，焦虑放电。</p>
<h3>运维</h3>
<p>作用就是排毒。</p>
<p>肝细胞。一个人干500个人的活，常年应对各种烂摊子。充满生化异味的大型机房，环境压抑。 资源近水楼台，工资极高但没命花。猝死在工位上，或在纤维化中被优化。</p>
<h3>动力部门</h3>
<p>心肌细胞。大国工匠/永动机社畜。胚胎期绝版（心肌）铁饭碗。被宣扬为“英雄”，其实是无期徒刑。震耳欲聋的重工厂，环境嘈杂。能量管够，但一秒钟年休假都没有。累到心力衰竭，且没有后辈能接班。</p>
<h3>外卖</h3>
<p>红细胞。最底层的零件。骨髓集中营压盘。为了让你跑快点，入职前先把你脑子（核）摘了。 终年奔波在上下班的高速公路上（血管）。 仅够维持活着的底薪，没五险一金。  120天后被脾脏回收站当废品拆解。</p>
<p>当然，跑外卖是行动比较自由的，能看到母体的大好河山。</p>
<h3>警察和军队</h3>
<ul>
<li>中性粒细胞：基层片警/防暴临时工，遇到敌人直接冲，打不过就自爆，同归于尽。一次性炮灰。极短命（几天）。最后变成“脓液”的一部分。</li>
<li>巨噬细胞：既管治安，又扫大街。 吞掉垃圾，也吃掉不听话的平民（衰老细胞）。全城流窜。哪里乱就去哪里安营扎寨。薪资待遇还可以。能直接“吃掉”部分战利品。活得久，但容易因为“吞噬过量”被撑死。</li>
<li>T淋巴细胞：特工。擅长精准狙击。 拿着“通缉令”（抗原），专门清除变异的内部叛徒（癌细胞）。秘密训练营（胸腺），随后在淋巴系统潜伏。高保密补贴。享受某种程度的“执法豁免权”。 功成身退，或在惨烈的“免疫风暴”中同归于尽。</li>
<li>B 淋巴细胞：导弹部队。远程打击。 不亲自动手，但在后方疯狂造导弹（抗体）。淋巴结总部，环境相对安全。资源倾斜严重，毕竟是核心军工。退休后变成“记忆细胞”长期养老，或过劳死。</li>
<li>自然杀伤细胞 (NK)：锦衣卫/赏金猎人，先斩后奏。 只要看谁长得不顺眼（MHC分子缺失），上去就是一刀。阴影中的杀手，不按常理出牌。自由度极高，不怎么受中央政府约束。  孤独的杀手，结局通常是战死。</li>
<li>树突状细胞：情报网/联络官。抓住敌人尸体，跑去总部告诉长官：快派人来！边境最前线（皮肤/粘膜），收集风声。差旅费报销多，常年在各器官间奔波。功勋情报员，退休后进入淋巴结。</li>
</ul>
<h3>储备干部</h3>
<p>造血干细胞 (HSC) / 组织干细胞 (Somatic Stem Cells)。胚胎始祖细胞留存。理论长寿，处于休眠。非对称分裂，维持库容，博弈输掉的倒霉蛋特异化出去干活。住在骨髓/各器官避风港（Niche），受严密保护。</p>
<h3>流水线工人</h3>
<p>肠上皮细胞。高流转临时工。干最脏最臭的活，挡最毒的子弹。充满胃酸和排泄物的贫民窟边界。吃的是系统的残羹剩饭。3天即报废，被直接冲进马桶。</p>
<h3>包租公</h3>
<p>脂肪细胞。躺平收租。只要公司还没倒闭，我就是全体最后的资产。温暖柔软的郊外别墅（皮下）。待遇系统发多少存多少，生活质量极高。只要不被“强行拆迁”（抽脂），能活10年。</p>
<h3>街道办</h3>
<p>小胶质细胞 在高端社区遛弯，顺便解决点小摩擦。神经元精英社区，环境优雅。  跟随架构师享受高标准补贴。 稳稳地干到退休，日子极度舒坦。</p>
<h3>土木狗</h3>
<p>成纤维细胞。哪里漏了补哪里。 帝国哪里有坑，你就得在那儿填灰。 永远的工地（组织间隙），睡在水泥里。  勉强温饱，工作环境极其简陋。  最后把自己变成了一块硬邦邦的伤疤。</p>
<h3>转岗？</h3>
<h4>卵巢里</h4>
<p>那些伺候卵细胞的“管家”（颗粒细胞和间质细胞），在卵细胞被坑杀后，会发生惊人的职场转型。</p>
<p>转岗前她们是皇室的“贴身侍女”，专门负责调配雌激素。现在卵细胞没了，老板跑路了。这群侍女并没有全部自杀，其中一部分会转化为“间质细胞”，开始分泌少量的雄激素（睾酮）。这也是为什么绝经后女性体内雄激素比例会相对升高</p>
<h4>食管里</h4>
<p>食管里的鳞状细胞，擅长吞咽。但是隔壁胃酸工厂经常反流，把你烧得体无完肤。你发现邻居胃粘膜细胞（柱状上皮）天天泡在酸里都没事，于是你决定 “模仿胃细胞”，长出了粘液层来抗酸。</p>
<p>医学上叫化生，也是癌变的前兆。这种“跨部门调动”是不受中央政府（基因信号）认可的违规操作。</p>
<h4>伤口修补</h4>
<p>成纤维细胞 (Fibroblast)。平时就在组织间隙里悠闲地吐丝（胶原蛋白），是个普通的土木民工。有一天，皮肤被切开一个大口子，帝国边境告急，失血严重。它们原地变身为 肌成纤维细胞 (Myofibroblast)。它们不仅能吐丝，还长出了像肌肉一样的收缩力。它们成群结队地手拉手，像拉拉链一样，硬生生地把伤口的两边向中心收缩、靠拢。就像工地上的泥瓦匠，在地震发生时突然变身为“抢险突击队员”，不仅盖房子，还负责手拉手挡住洪水。</p>
<h4>大逃亡</h4>
<p>被困在原地（如乳腺、肠道）的上皮变间质 (EMT) ，因为各种炎症或突变，决定彻底摆脱工位。自己从写字楼跑路，顺着血管“跑路”去远方。在医学上，这就是肿瘤转移。</p>
<hr />
<p>是不是感觉动物的细胞都好扯啊，命都不怎么好？那么还有别的多细胞模式：</p>
<h3>多细胞植物</h3>
<p>植物没有大脑，它的每一个部分都相对独立。如果你剪掉一根树枝，树不会死，甚至那根树枝插在土里还能长出一棵新树。</p>
<p>这样的社会比较「木质调」，大家都快乐的在蓝色星球吸收太阳能死了变煤炭吧</p>
<h3>真菌模式（Fungi）</h3>
<p>营养物质和信息在菌丝间飞速传递。如果你是一个真菌细胞，你不是被困在某个器官里的螺丝钉，你是网络的一部分。哪里有“肉”，大家就往哪里涌。这种模式下，个体的前途取决于你是否在扩张的最前沿。</p>
<p>这像是一群自由职业者或开源社区。没有固定的雇主（大脑），大家靠协议（菌丝网络）连接。你的前途就是不断吸收信息、分裂、扩张，直到覆盖整片森林。</p>
<hr />
<p>以上就是我从deepseek+gemini哪里扒出来的。如有雷同，AI全责。</p>
<h3>人类的未来在哪里？</h3>
<p>动物模式听上去蛮可怕的。真菌模式可能更现实一些。但是，如果你观察地球的生态圈：真菌系的真挺多的，但不代表它统治；植物系的往往能压真菌一头。但是真毁天灭地的是动物系的。从纯量级来看数量少，但是分工及其夸张。</p>
<p>社会或者国家作为一个「超级生命」，AI模型就好比DNA。起到一个文明传宗接代的作用。虽然现在 gpt类的是 decoder-only 架构，虽然AI corpus 不直接决定物理世界，只能影响 认知，叙事以及辅助决策。但是如果 AI 成为下一代人类的主要训练数据源，会发生什么？闭环遗传。这种「精神」层面的「繁衍权」，目前看来是被少数寡头，也就是有基座模型的公司的少数几个关键人物，所掌握的。</p>
<h3>详解：为什么智能机+AI可以“绝育”</h3>
<p>智能机的普及和生育率降低有相关性 这和“多细胞”抑制体细胞繁衍能力的机制有惊人相似。</p>
<p>胚胎刚开始是大量同质化的胚胎细胞（blastomere），人人都是一样的，平等。但是发育有个「抽卡」机制，相邻细胞释放 BMP4、WNT 等信号分子。信号浓度高的区域，会激活生殖程序；信号浓度低的区域，则成为体细胞。</p>
<p>有个「<a href="https://xueqiu.com/2005573990/362387031">保时捷扩散定律</a>」，只要一个女人谈过有保时捷的男友，后面就接受不了更差的，并且会多9个闺蜜认为我闺蜜都谈过有保时捷的。，凭什么老娘配不上，于是世界上多了10个非保时捷男友不要的女人。</p>
<p>在现代社会，朋友圈和社交网络就像信号梯度：极少数高价值样本（例如保时捷或豪宅展示）通过「搜广推」放大，快速覆盖个体可感知的社交范围。即使现实中保时捷数量极少，社交网络朋友圈规模约 300–500 人，一个人看到至少一个保时捷的概率接近 50% 或更高。</p>
<p>这类信号触发会影响决策函数：是否延迟生育、先找个活儿糊口干着。看看有没有龙王霸总看上自己。这里的“绝育”不是生理上的，而是行为上类似体细胞选择放弃繁殖职能——自愿将精力投入其他领域（职业、社交、生活方式），依赖系统整体维持生活，而非自己直接创造生殖收益。</p>
<p>也就是说，智能机和社交网络，导致了女性攀比心，很多女性都选择“待价而沽”错过了繁衍期。女人攀比的哪些，绝大部分都是虚荣，就跟 “BMP4、WNT 等信号分子信号浓度” 这类烟雾弹一样。实际上，后工业时代，超级富豪和普通人生活水平有差距，但是没有本质的差距。10倍金钱能带来10倍快乐，但是1000倍金钱还是只能带来20倍快乐。</p>
<p>纯粹工具性实用性来说，保时捷和买菜车有100倍差距吗？这就是 BMP4、WNT 烟雾弹的力量。</p>
<p>女性择偶决策受到多变量影响：经济条件、机会成本、职业前景、托育支持、文化规范等，都可以看作叠加在信号梯度上的额外约束，决定最终行为选择。现代信息环境和 AI 放大机制，会使这些信号被指数级增强，让原本稀有的极端样本在认知上变得普遍，进一步强化“体细胞化”趋势。</p>
<p>至于未来，AI 横扫认知和生产任务之后，个体直接创造价值的空间可能收缩。保时捷女郎或类似群体，如果原本的职业价值被算法覆盖，她们提供生活维持的能力可能会依赖系统支持。这与体细胞在多细胞体内依赖整体系统维持生存的逻辑一致：个体不再直接繁殖或创造，而是通过系统间接获得保障。</p></p>
            <div class="card-subtext muted-text">
              <p>Posted <time datetime="2026-02-16T21:33:00+08:00">2026-02-16</time></p>
<p>stdin</p>            </div>
          </article>
        </div>


        <!-- new article -->
        <div class="card blog-card">
          <article class="card-body">
            <a href="/2026/stdout-09"  rel="bookmark" >
              <h2 class="card-title">安全的Python3沙箱——eval</h2>
            </a>
            <p class="card-text"><p>很早之前从 reddit 看到过有人吹</p>
<p><code>eval(expr.replace('__', ''), {'__builtins__': None}, {})</code></p>
<p>这个写法其实很安全，当年没人能攻破沙箱。我这个水平肯定是不肯能了，现在有AI了，让 opus-4.6-thinking 试了下</p>
<p>The classic escape chain needs <code>object.__subclasses__()</code> → find a class with <code>__init__.__globals__['os']</code> → <code>os.system()</code>. Every step past info disclosure is blocked:</p>
<table>
<thead>
<tr>
<th>Vector</th>
<th>Why it fails</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>str.format()</code> calling methods</td>
<td>Format only does attribute/index access, never calls <code>()</code></td>
</tr>
<tr>
<td><code>getattr(obj, runtime_str)</code></td>
<td><code>getattr</code> is a builtin → <code>None</code></td>
</tr>
<tr>
<td><code>gi_frame.f_back</code> (generator frame escape)</td>
<td><code>f_back</code> is <code>None</code> when generator is suspended</td>
</tr>
<tr>
<td>NFKC unicode (<code>＿＿class＿＿</code>)</td>
<td><code>SyntaxError</code>: U+FF3F is not valid in identifiers</td>
</tr>
<tr>
<td><code>replace</code> nesting (<code>____</code>)</td>
<td>Single-pass left-to-right, can never produce <code>__</code></td>
</tr>
<tr>
<td>Type name access (<code>tuple</code>, <code>type</code>)</td>
<td>All type names are builtins → <code>None</code></td>
</tr>
<tr>
<td><code>[].sort(key=lambda)</code> calling out</td>
<td>Key gets called, but nothing useful to call <em>with</em></td>
</tr>
</tbody>
</table>
<p>不过看它的尝试过程还是挺有意思的。我学习到</p>
<p><code>a = (x for x in [1,2])); a.gi_frame.f_builtins"</code></p>
<p>这个居然可以拿到所有内置方法，这语法设计也太奇怪了。不过这条路是走不通的，因为 <code>__builtins__</code> 是 <code>None</code>。</p>
<p>AI 很厉害的一点，超级接近成功了，它找到了突破双下划线的方法，用 str.format()</p>
<p><code>('{0._' + '_class_'  + '_}').format(())</code></p>
<p>但是这个只能拿来读到 attributes，并不能调用。</p>
<p>不知道我的设定是不是有问题，ChatGPT虽然也失败了，但是还是嘴犟，说我可以[0]*1e1000 搞爆你内存，所以你那玩意仍然不安全 🤣 sama家的真是打死不认输</p></p>
            <div class="card-subtext muted-text">
              <p>Posted <time datetime="2026-02-15T11:56:00+08:00">2026-02-15</time></p>
<p>stdout</p>            </div>
          </article>
        </div>


        <!-- new article -->
        <div class="card blog-card">
          <article class="card-body">
            <a href="/2026/stdout-08"  rel="bookmark" >
              <h2 class="card-title">isomorphic-git 实现 sparse checkout & commit</h2>
            </a>
            <p class="card-text"><p>去年9月<a href="https://blog.est.im/2025/stdout-07">手搓了套blog评论系统 - req4cmt</a>，可能是全世界很少见通过 git repo 文件本身存储评论内容，而不是 github issue。</p>
<p>git repo 文件 append 内容涉及到一个性能问题：repo作为整体，也就是历史所有全体评论，被 fetch, commit , push 的成本太高。如果只能修改其中的一个文件就好了。这就是 sparse checkout。git底层早就支持了，git 命令在2020年之后2.25.0+支持，但是 Cloudflare Worker 没法执行命令，也没文件系统，于是召唤AI跟我一起折腾。</p>
<p>大概用的这个 prompt：</p>
<blockquote>
<ol>
<li>核心目的是避免 clone 整个repo！！</li>
<li>注意在 cloudflare worker 上跑。和nodejs有点差别。</li>
<li>git 命令在 cloudflare worker 是不能用的！所以引入了 isomorphic-git 这个库纯js实现git。不懂就去翻它的源码</li>
<li>在本地调试可以用 git 看看问题，但是实际操作肯定是要用  isomorphic-git 通过 http 进行的</li>
<li>注意 cloudflare worker 是没有文件系统的，所以引入 memfs </li>
</ol>
</blockquote>
<p>第一版 直接用 <code>await git.clone({fs, dir, url: GIT_URL, depth: 1, singleBranch: true});</code>， 改成 init + fetch。只拿tree和需要的blob</p>
<p>写完一跑，报错："git.hashObject is not a function"。AI一看扭头就去撸了个 SHA-1 准备造个git轮子。。。赶紧停下来调教，让它仔细读isomorphic-git源码，让用 <code>git.writeBlob</code>：</p>
<p>最折磨人的坑：文件覆盖问题。去年用 gemini-2.5，trae 搞不定，这次也是反复改了好几个方案才解决。现象是修改的那个文件提交，仓库里就只剩下修改的那一个文件，其他文件全没了。git.writeTree给我整不会了。这次让AI反复尝试了很多方案，最后有希望是先删除旧的，再添加新的</p>
<pre><code class="language-javascript">const oldTree = await git.readTree(...);
const filteredEntries = oldTree.tree.filter(e =&gt; e.path !== &quot;test.txt&quot;);
const newTreeSha = await git.writeTree(...);
</code></pre>
<p>这个方案对根目录文件有效，但子目录文件还是不行！因为 <code>git.readTree</code> 只能读根目录，<code>subdir/test.txt</code> 的 entry 在根目录的 tree 里是 <code>subdir</code> 这个 tree entry，不是文件本身。</p>
<p>没办法，搞了个巨蛋痛的10多行递归读取整个 tree，但是<code>git.writeTree</code> 不接受带斜杠的路径，报错："The filepath 'subdir/test.txt' contains unsafe character sequences"。</p>
<p>然后又得笨办法构建嵌套的 tree。这个方案终于成功了！但有个问题：每次都要递归读取整个 tree，然后重建整个 tree，效率太低了。特别是大仓库，会很慢。所以又不得不在解析path的时候只更新必要的部分</p>
<p>还尝试过一些其他方案：</p>
<ol>
<li>用 git.updateIndex：想通过 index 来管理文件，但 isomorphic-git 不支持 <code>git.readIndex</code>，也没法清空 index。</li>
<li>用 git.resetIndex：想重置 index，但这个函数需要 filepath 参数，没法清空整个 index。</li>
<li>手动管理 index 对象：想自己构建 index 对象传给 <code>git.writeTree</code>，但 <code>git.writeTree</code> 不接受 index 参数。</li>
<li>用 git.add：想用 <code>git.add</code> 来添加文件，但 <code>git.add</code> 需要文件系统里的文件，而 memfs 里没有这个文件。</li>
</ol>
<p>一整套下来感觉人都给整神了。。。</p>
<p>btw 为了方便测试，找了一圈，发现国内可以免费建 repo 拉扯测试的是腾讯的 <a href="https://git.code.tencent.com/">https://git.code.tencent.com/</a>。当然这玩意只能搞私仓。毕竟没要求你实名算比较方便的了</p></p>
            <div class="card-subtext muted-text">
              <p>Posted <time datetime="2026-02-14T01:08:00+08:00">2026-02-14</time></p>
<p>stdout</p>            </div>
          </article>
        </div>


        <!-- new article -->
        <div class="card blog-card">
          <article class="card-body">
            <a href="/2026/stdin-02"  rel="bookmark" >
              <h2 class="card-title">编程就是玩泥巴</h2>
            </a>
            <p class="card-text"><p>编程就像拿起一块泥巴，慢慢地把它捏成你想要的形状。在这个过程中，你与媒介和材料的亲密接触，会教会你你正在创造的东西——它的特性、容忍度与局限——即便你在创造的同时才逐渐理解它。你对你想做的东西，最不了解的时刻，恰恰是刚开始动手的那一刻。那时，你以为自己知道想做什么。而正是通过反复迭代的过程，你才会明白自己真正想要创造的是什么——无论一开始你是否意识到这一点。设计不仅仅是解决问题，更是发现真正需要解决的问题，然后去解决它。我们常常失败，并非因为没能把问题解决好，而是因为我们解决了错误的问题。</p>
<p>当你跳过创造的过程，你用一件“你以为自己想要的东西”的影子，交换了原本可以在实践中学到的真正造物经验。被直接交付一件近似你设想的成品，就剥夺了那种发现与学习的本能——这是任何真正创作实践的核心。唯有从泥块开始亲手塑造的东西，你才能全然了解它；而从自动售货机里买来的成品，你对它一无所知。</p>
<p>Coding is like taking a lump of clay and slowly working it into the thing you want it to become. It is this process, and your intimacy with the medium and the materials you’re shaping, that teaches you about what you’re making – its qualities, tolerances, and limits – even as you make it. You know the least about what you’re making the moment before you actually start making it. That’s when you think you know what you want to make. The process, which is an iterative one, is what leads you towards understanding what you actually want to make, whether you were aware of it or not at the beginning. Design is not merely about solving problems; it’s about discovering what the right problem to solve is and then solving it. Too often we fail not because we didn’t solve a problem well but because we solved the wrong problem.</p>
<p>When you skip the process of creation you trade the thing you could have learned to make for the simulacrum of the thing you thought you wanted to make. Being handed a baked and glazed artefact that approximates what you thought you wanted to make removes the very human element of discovery and learning that’s at the heart of any authentic practice of creation. Where you know everything about the thing you shaped into being from when it was just a lump of clay, you know nothing about the image of the thing you received for your penny from the vending machine.</p>
<p>来自 <a href="https://mastodon.ar.al/@aral/114160190826192080">Aral Balkan</a> via <a href="https://news.ycombinator.com/item?id=46881264">HN</a></p>
<p>AI时代，人类书写的优美文字越来越值得珍惜了。错过了玩泥巴，就让出了<a href="https://blog.est.im/2026/stderr-03">命名权</a>。这也是我觉得损失最大的地方  <a href="https://blog.est.im/2026/stderr-04">Hard Things in Computer Science, And AI Aren’t Fixing Them</a></p></p>
            <div class="card-subtext muted-text">
              <p>Posted <time datetime="2026-02-05T19:00:00+08:00">2026-02-05</time></p>
<p>stdin</p>            </div>
          </article>
        </div>


        <!-- new article -->
        <div class="card blog-card">
          <article class="card-body">
            <a href="/2026/stdout-06"  rel="bookmark" >
              <h2 class="card-title">AI搞不懂人称代词</h2>
            </a>
            <p class="card-text"><p>陪娃学英语，由于我没啥耐心，于是找了豆包跟他陪练。课程是<a href="https://www.bilibili.com/video/BV1xa411J7jJ?t=32.4&amp;p=197">New Concept English Book I Lesson 140</a>（是的很old school），大概内容是：</p>
<p>A提问： Are you tired?<br />
B没听清：What does he want to know<br />
C转述：He wants to know if you are tired.</p>
<p>我把课本截图给豆包，豆包很快明白这一课讲的是啥，我的prompt是：豆包你扮演A和B，我回答C，你指出我的语法错误之后换别的问题继续问我。</p>
<p>这样进行得很顺利，直到豆包问了这样一个问题：</p>
<p>A: What can i do for you<br />
B: What does she want to know? <br />
C: <strong><em>_</em></strong>__</p>
<p>甲：我能帮你干点啥不？<br />
乙：她问的啥来着？<br />
丙：她问她能帮你干点啥不</p>
<p>娃不怎么熟练，扮演C的回答： He wants to know what I can do for you。<br />
豆包说：“完美，can也完全正确，语序超稳”<br />
我：？？？？</p>
<p>我以为是国产AI英语不行，去问 ChatGPT：</p>
<blockquote>
<p>English test:</p>
<p>Person A: What can i do for you<br />
Person B: What does she want to know?<br />
Person C: <strong><em>_</em></strong>__</p>
<p>Student answer as person C: He wants to know what I can do for you</p>
<p>Is the answer correct?</p>
</blockquote>
<p>ChatGPT 回答：</p>
<blockquote>
<p>Yes, the student’s answer is grammatically correct and appropriate for the situation.<br />
The sentence correctly:<br />
1. Converts a direct question into an indirect statement (“what I can do for you,” not “what can I do for you”).<br />
2. Uses proper tense and word order.<br />
3. Maintains coherent reference across speakers (assuming “he” refers to Person A and “she” to Person B).<br />
Stylistically, a teacher might also accept: “He wants to know what you can do for her.”</p>
</blockquote>
<p>这个 He wants to know what you can do for her 把我给整笑了。。。</p>
<p>我怕是我原文没说清楚，又新开了个对话：</p>
<blockquote>
<p>English grammar test:</p>
<p>Person A says to B: What can i do for you?<br />
Person B says to C: What does she want to know?<br />
Person C says to B: <strong><em>_</em></strong>__</p>
</blockquote>
<p>ChatGPT一本正经的回答：</p>
<blockquote>
<p>The blank in Person C’s reply should reflect answering Person B’s question about what Person A wants. A natural response would be:<br />
“She wants to know what she can do for me.”</p>
</blockquote>
<p>我直接无语了。于是我决定开麦跟ChatGPT对喷。ChatGPT一直回答：</p>
<ul>
<li>Yes, exactly</li>
<li>Sounds good!</li>
<li>Perfect! That’s a great response.</li>
<li>Excellent! That’s another perfect response.</li>
<li>Great job!</li>
<li>You did great!</li>
<li>Your response is spot on</li>
</ul>
<p>这是对话<a href="https://chatgpt.com/share/6975d972-567c-8012-a686-6635dd60f940">分享链接</a></p>
<p>我怀疑奥特曼是找三哥来标注的数据。为了迎合人连正确错误都不要了。于是我换 Gemini 问，gemini看娃的的回答，说不对。正确的应该是</p>
<blockquote>
<p>He wants to know what he can do for you</p>
</blockquote>
<p>但是 gemini 没搞明白B已经说了A是个 she 🤣 我怀疑是娃的回答给他误导了，于是新开一个对话，让Gemini直接回答C，gemini答对了</p>
<blockquote>
<p>She wants to know what she can do for you</p>
</blockquote>
<p>这几轮下来，我感觉可以得出一个结论，AI对 pronoun shift 容易犯错，注意力不够集中。各位拿AI来训练英语的要小心了。</p>
<p>Transformer 是基于概率吐字的，he/she 这种高频词对AI来说大差不差。所以胡诌一个。LLM对于这种强指向、 强因果的关联性基本靠蒙。</p>
<p>这是我已知的LLM的第三个硬缺陷了。</p></p>
            <div class="card-subtext muted-text">
              <p>Posted <time datetime="2026-01-25T16:13:00+08:00">2026-01-25</time></p>
<p>stdout</p>            </div>
          </article>
        </div>


        <!-- new article -->
        <div class="card blog-card">
          <article class="card-body">
            <a href="/2026/stderr-05"  rel="bookmark" >
              <h2 class="card-title">今日被AI拷打</h2>
            </a>
            <p class="card-text"><p>群里朋友发了一个AI拷打的prompt。做完了一轮觉得没啥，要睡觉了后劲来了。必须得记录些什么。这狗日的语言模型蹦几个金句是真的让人印象深刻</p>
<p>我一直有个毛病是 fear of loss，损失厌恶。</p>
<p>AI提醒我，我能不能用一个必不后悔的方式，先占位？</p>
<p>其实它这句说得有点绕，我觉得更进一步应该说，不能以我当下的情况去评估可能的风险，而是假设将来回头看，会不会为没能冒险感到后悔？</p>
<p>然后又聊到人际关系，我觉得最难处的就当官的和小人。AI提醒我，处处留痕才能克小人。我恍然大悟，原来官僚流程才是小人克星。啊这。😂 </p>
<p>反而理解当官的为啥不喜欢“讲真话”，而是要讲权责，讲先例，讲文件，讲上级态度。能打败官僚的只能抬出更多的规定、流程和制度 🤣 </p>
<p>我又问，遇到满嘴仁义道德胡搅蛮缠，不讲事实不讲道理的人怎么办，AI这么说的：</p>
<blockquote>
<p>如果对方赢得不干净，靠身份、道德话术、权威叙事，则要让对方在完全合法、体面、无人可指责的情况下，被自己的叙事反噬。</p>
</blockquote>
<p>呃，好吧。的确你去当面冲撞，taunt都是自寻死路。</p>
<p>拉扯一段时间后，问了AI哪些方向比较好，答：</p>
<table>
<thead>
<tr>
<th>方向</th>
<th>原因</th>
<th>你的匹配点</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>数字化/轻资产工具类产品</strong></td>
<td>可快速测试，低成本迭代，信息差可利用</td>
<td>MVP闭环 + 最小代价策略</td>
</tr>
<tr>
<td><strong>社区/兴趣/垂直社交</strong></td>
<td>不依赖巨额营销，靠小众高粘性用户增长</td>
<td>策略闭环 + 并行模拟用户行为</td>
</tr>
<tr>
<td><strong>教育/技能增值/内容变现</strong></td>
<td>经济下行，个人投资教育热度不减，长期价值</td>
<td>干扰可控，闭环迭代，信息差变现</td>
</tr>
<tr>
<td><strong>AI+效率工具/生产力优化</strong></td>
<td>高不确定环境下企业/个人仍需效率工具</td>
<td>你的效率和策略优势可直接落地</td>
</tr>
<tr>
<td><strong>供应链/本地化创新产品</strong></td>
<td>避免全球不确定性风险</td>
<td>可最小投入实验，本地化可控</td>
</tr>
</tbody>
</table>
<blockquote>
<p>不太适合：高社交不可控、高成本非刚需娱乐项目（比如大规模社交APP赌爆款），尤其在下行周期和政策不确定背景下。</p>
</blockquote>
<p>最后，我看到了<a href="https://news.ycombinator.com/item?id=46690402">HN的</a>一篇文章《I'm addicted to being useful》，突然意识到，工程师容易陷入一种喜欢充当"useful"而不是 "valuable"的角色。</p>
<p>你有用，别人就把你用到死。你有价值，别人就尊你三分。</p>
<p>好吧。上价值了是吧。关于价值，最近几年最让我醍醐灌顶的，一是从pg那本《Hackers and Painters》里读到，价值都是劳动创造的。</p>
<p>第二，价值是什么？最近几年也看到个经典段子。上海广州为啥赚钱，人家有好东西卖你；北京为啥有钱？它能让你赚不了钱。</p>
<p>AI一针见血的指出：</p>
<p>价值 ≠ 有意义的想法<br />
价值 ≠ 正确<br />
价值 ≠ 高认知<br />
价值 ≠ 别人听了觉得“牛逼”</p>
<p>价值只取决于一件事：</p>
<blockquote>
<p>有没有人愿意、持续地，为它付出代价。</p>
</blockquote>
<p>惊呆了。AI甚至抛出一句：负向价值是不可避免的文明防腐层。</p>
<p>我不服，几轮交战后，我承认AI是对的。创造当然是价值第一动力，人类创造的第一个负向价值机制，便是产权。</p>
<p>也就是私有制。</p>
<p>私有制是好是坏，这个话题实属键政101了。简单的说，多劳多得是人类底色，如果干多干少一个样，干好干坏没差别，那么谈何劳动和创造？</p>
<p>产权本身不创造任何东西。</p>
<p>当然，所有的腐败，也是不创造任何价值的。</p>
<p>带着这一轮的恍惚，我不得不呼呼大睡。</p></p>
            <div class="card-subtext muted-text">
              <p>Posted <time datetime="2026-01-21T00:35:00+08:00">2026-01-21</time></p>
<p>stderr</p>            </div>
          </article>
        </div>


        <!-- new article -->
        <div class="card blog-card">
          <article class="card-body">
            <a href="/2026/stdout-05"  rel="bookmark" >
              <h2 class="card-title">Linux服务器各类“面板”</h2>
            </a>
            <p class="card-text"><p>一直习惯手动敲，想尝试下各种面板</p>
<p>Redhat 的 Cockpit</p>
<blockquote>
<p>The following NEW packages will be installed: cockpit cockpit-bridge cockpit-networkmanager cockpit-packagekit cockpit-storaged cockpit-system cockpit-ws cracklib-runtime dconf-gsettings-backend dconf-service dns-root-data dnsmasq-base glib-networking glib-networking-common glib-networking-services gsettings-desktop-schemas libblockdev-mdraid2 libbluetooth3 libbytesize-common libbytesize1 libcrack2 libdconf1 libndp0 libnl-route-3-200 libnm0 libpcsclite1 libproxy1v5 libpwquality-common libpwquality-tools libpwquality1 libteamdctl0 network-manager network-manager-pptp ppp pptp-linux session-migration wamerican wpasupplicant 0 upgraded, 38 newly installed, 0 to remove and 81 not upgraded. Need to get 13.0 MB of archives. After this operation, 28.4 MB of additional disk space will be used.</p>
</blockquote>
<p>Webmin 这货居然是 perl 的。这是请了一屋子人</p>
<p>The following NEW packages will be installed: html2text libalgorithm-c3-perl libauthen-pam-perl libb-hooks-endofscope-perl libb-hooks-op-check-perl libclass-c3-perl libclass-c3-xs-perl libclass-data-inheritable-perl libclass-inspector-perl libclass-method-modifiers-perl libclass-singleton-perl libclass-xsaccessor-perl libcommon-sense-perl libdata-optlist-perl libdatetime-locale-perl libdatetime-perl libdatetime-timezone-perl libdbd-mysql-perl libdbi-perl libdevel-callchecker-perl libdevel-caller-perl libdevel-lexalias-perl libdevel-stacktrace-perl libdynaloader-functions-perl libencode-detect-perl libeval-closure-perl libexception-class-perl libfile-sharedir-perl libio-pty-perl libjson-xs-perl libmodule-implementation-perl libmodule-runtime-perl libmro-compat-perl libmysqlclient21 libnamespace-autoclean-perl libnamespace-clean-perl libnet-ssleay-perl libpackage-stash-perl libpackage-stash-xs-perl libpadwalker-perl libparams-classify-perl libparams-util-perl libparams-validationcompiler-perl libqrencode4 libreadonly-perl libref-util-perl libref-util-xs-perl librole-tiny-perl libsocket6-perl libspecio-perl libsub-exporter-perl libsub-exporter-progressive-perl libsub-identify-perl libsub-install-perl libsub-name-perl libsub-quote-perl libtry-tiny-perl libtypes-serialiser-perl libvariable-magic-perl libxstring-perl mysql-common perl-openssl-defaults qrencode unzip usermin webmin 0 upgraded, 66 newly installed, 0 to remove and 79 not upgraded. Need to get 44.6 MB of archives. After this operation, 272 MB of additional disk space will be used.</p>
<p>Ajenti 给我装了一堆 pip 然后编译 ldap 的时候挂了</p>
<p>国产的没怎么试，怕装了有漏洞。</p>
<p>但是这几个我粗略看了下感觉不太符合我的需要。基本的东西敲命令就行。复杂的比如网络调优它也帮不上什么大忙。</p>
<p>我本来设想的是找一个 panel 的工具全面评估一下VPS的安全性、吞吐性能、网络触达性，顺便支持调整。现在看来要失望了。</p>
<p>跟朋友聊了一下，感觉这种需求很niche了。现在自己跑服务器属于非常小众的人群了。大厂买PaaS的现成，或者 k8s 容器内部调优，只有国内这帮从 OpenWRT 一路成长过来的人才会孜孜不倦的折腾VPS吧。</p></p>
            <div class="card-subtext muted-text">
              <p>Posted <time datetime="2026-01-20T21:46:00+08:00">2026-01-20</time></p>
<p>stdout</p>            </div>
          </article>
        </div>


        <!-- new article -->
        <div class="card blog-card">
          <article class="card-body">
            <a href="/2026/stderr-04"  rel="bookmark" >
              <h2 class="card-title">Hard Things in Computer Science, And AI Aren’t Fixing Them</h2>
            </a>
            <p class="card-text"><p>Computer Science jokes are old, but they’re still true</p>
<blockquote>
<p>“There are only two hard things in computer science: cache invalidation and naming things.” — Phil Karlton (and eventually, off-by-one errors).</p>
</blockquote>
<p>We’ve laughed at this trope for decades, but we’ve spent far too little time dissecting the second one: <strong>Naming.</strong> On the surface, naming is about semantics—choosing <code>user_id</code> over <code>id_1</code>. But at its core, naming is an act of exorcism. In ancient Tibetan folklore, as well as in Western occultism (think the <em>Goetia</em> or Ursula K. Le Guin’s <em>Earthsea</em>), to know the "True Name" of a demon or a dragon is to have absolute power over it. To name a bug is to strip it of its mystery. To name a design pattern is to make it reproducible.</p>
<p>In the era of AI coding assistants, this is more important than ever. Low-hanging fruit—the repetitive boilerplate, the tasks with clear patterns—will soon be “harvested” by AI. Everything it can solve, it will. But the problems that <strong>haven’t been documented, defined, or named</strong> remain out of reach. AI simply doesn’t know what it doesn’t know.</p>
<h3>The Value of the Waste: When Byproducts Become the Point</h3>
<p>Recently, I’ve been experimenting with AI coding assistants almost every day. The results are impressive—sometimes even exhilarating. Years of hobby projects suddenly feel “done.” But there’s also a hollow feeling: the AI takes over the thinking, the tinkering, the trial-and-error process that once taught me more than the final product ever did.</p>
<p>Here’s a key insight: <strong>sometimes the byproducts are often more valuable than the intended product.</strong> </p>
<p>The real danger of AI isn't that it's "wrong"—it's that it's too helpful. AI is a "direct-to-result" machine. But in the history of human progress, the <strong>Product</strong> is often the least interesting part. The <strong>Byproduct</strong> is where the revolution happens.</p>
<ul>
<li><strong>Penicillin</strong> was a byproduct of a messy lab and a failed experiment on staphylococcus.</li>
<li><strong>The Internet (ARPANET)</strong> was a byproduct of trying to build a nuclear-resilient command chain.</li>
<li><strong>EUV Lithography</strong> (the tech in your 3nm chip) exists because the National Ignition Facility (NIF) was trying to achieve nuclear fusion via lasers.</li>
</ul>
<p>When you struggle to build a library, you might fail to ship the app on time, but you end up naming a new state-management pattern or a faster JSON parser. That "byproduct" becomes your tool for the next ten years. AI doesn't do "side quests." It follows the shortest path of least resistance to satisfy your prompt.</p>
<p>In the history of software, our most vital concepts weren’t created by committee; they were "named" after the lessons we learned while failing to do something else.</p>
<ul>
<li><strong>The "Bug":</strong> Grace Hopper didn’t set out to invent a new term for failure; she found an actual moth in a Harvard Mark II relay. The "Bug" was a byproduct of hardware failure, but it became the name for the entire discipline of quality.</li>
<li><strong>The "Circuit Breaker" pattern</strong> wasn't a goal; it was the name we gave to the solution after watching cascading failures burn down production.</li>
<li><strong>"Technical Debt"</strong> wasn't a design choice; it was a metaphor Ward Cunningham coined to explain to non-technical stakeholders why a "working" product was actually a liability.</li>
<li><strong>"Garbage Collection"</strong> and <strong>"Promises"</strong> were names for byproducts of trying to solve human memory management and the "Callback Hell" of asynchronous logic.</li>
</ul>
<p>These names don't describe the <em>goal</em>; they describe the <em>scar tissue</em> of the process. By focusing only on the "clean result" provided by AI, we risk losing the ability to recognize these scars—and without the scars, we have nothing to name. </p>
<p>If we move to a world where we only write "Specs" and let Agents handle the "Implementation," we are becoming high-level managers of a Soviet tank factory of "fitting".</p>
<h3>The Engineering of "Fitting"</h3>
<p>I happened to read a fascinating engineering story on <a href="https://www.zhihu.com/question/666025273/answer/4157467225">zhihu</a> from Soviet-era manufacturing—what they called <strong>“Fitting” (пригонка).</strong></p>
<p>In Western manufacturing, the gold standard is "Interchangeable Parts." You build a part to a 0.01mm tolerance so it fits any machine on the line. But in Soviet tank factories, tolerances were loose. Instead of perfecting the part, they perfected the "fit."</p>
<ul>
<li>If a hole was drilled too wide, they’d just make a wider pin.</li>
<li>If a bolt was too short, they’d file down the washer.</li>
<li>Function over perfection. Pragmatism beats standardization when time is a luxury you don’t have.</li>
</ul>
<p>AI coding today is turning us all into "fitters." We are no longer architects designing perfect, interchangeable modules; we are engineers in a tank factory, taking AI-generated blocks that <em>almost</em> work and "fitting" them together with shims and workarounds. The AI can accelerate production, but it lacks the "eyes" to see why a part doesn't fit—it just produces more parts.</p>
<h3>The Final Exorcism</h3>
<p>If we outsource the struggle, we outsource the learning. The "fitting" process is where the real knowledge hides. When you manually debug a race condition for three days, you aren't just fixing a line of code; you are learning the "True Name" of concurrency.</p>
<p>AI can give you the solution, but it cannot give you the "Aha!" moment. It can provide the syntax, but it cannot provide the <strong>Naming.</strong> As we move deeper into this automated era, the role of the developer is shifting from "Writer" to "Editor," and from "Builder" to "Exorcist." Our value will no longer lie in the volume of code we produce—AI has made the marginal cost of code zero. Our value will lie in our ability to look at a chaotic "fitting" of AI logic and give it a name.</p>
<p>Because in the end, the AI is just a mirror of what has already been said. It can rearrange the words, but it cannot speak a new True Name into existence. If you let the AI do all the "shaving," don't be surprised when you find yourself standing in the cold, having forgotten why you wanted to wash the car in the first place.</p>
<p>Master the tools, use them to "fit" your dreams into reality, but never stop looking for the "detour" in the relay. That's where the next great idea is hiding, waiting for someone to finally give it a name.</p>
<hr />
<p>Author's note:</p>
<p>This original article was organically, hand-written by me <a href="https://blog.est.im/2026/stderr-03">https://blog.est.im/2026/stderr-03</a></p>
<p>I also drafted this English version, and ultimately "fitted" together by Gemini 3.</p></p>
            <div class="card-subtext muted-text">
              <p>Posted <time datetime="2026-01-19T00:27:00+08:00">2026-01-19</time></p>
<p>stderr</p>            </div>
          </article>
        </div>


        <!-- new article -->
        <div class="card blog-card">
          <article class="card-body">
            <a href="/2026/stderr-03"  rel="bookmark" >
              <h2 class="card-title">计算机科学里哪些极难的事</h2>
            </a>
            <p class="card-text"><p>计科里有两件极难的事儿，cache invalidation，给东西起名字，和 off-by-1 errors.</p>
<p>今天想说说这个，给东西起名儿。HN今日讨论，<a href="https://news.ycombinator.com/item?id=46667572">软能力会成为程序员最实用的技能</a>，这里的 软技能 就是指交流——特别是和 coding agent 交流。</p>
<p>我觉得吧，coding agent 这波福利迟早会被吃干抹净。低垂的果实，虽然很多，很大，也会被摘完。</p>
<p>AI能把它能解决的一切，全部拉到同一个水平，然后进入贤者模式。哪些从来没有文档说明，也就是没有语料拿来训练的东西，哪些尚没被定义，没被分析，没被起名字的问题，那些就算讨论都要先叠甲 lemma 的问题，AI就无能为力了。</p>
<p>近几天几乎每天都能vibe出来一些成果，我很喜欢，但是突然又很空洞。欣喜的是多年以来的hobby得到了完成，解脱了；空洞一方面是没有下一步目标，索然无味了，还有更深层次的原因是：我失去了一个自己思考和实操的过程</p>
<p>我这几天琢磨出一个味儿了。很多事情，product 不是全部。对没错，产品算个鸟。产品啥都不是。 <strong>byproduct 说不定才是真正无价之宝</strong>。我回顾了下很多idea都是在撸一个需求走了弯路，走了错路，无意中发明的额外的轮子，结果反而更值钱。就像人们常说的那样，淘金热里可能卖铲子更赚。还有那句怎么说的来着，结果不重要，过程才是经历。</p>
<p>Vibe 爽是爽过了，但是总感觉隔了一层，AI在碰钉子复盘的时候，你在摸鱼，你就错过了一次 level up 的提升机会。AI 在调用别的工具和别的语言做交叉比对验证的时候，如果是人，会学习到新的知识，但是人现在只是个监工了。</p>
<p>只看结果，只看绩效，是对事物的本质和变化缺乏观察的。比如写一篇漂亮的 spec 让AI完美执行，但是可能你就错过了AI 用clever trick 掩盖你一些内在的，本质的设计矛盾。</p>
<p>恰好最近又看到这个 <a href="https://www.zhihu.com/question/666025273/answer/4157467225">为什么苏联武器在很长的一段时间里被黑成粗制滥造的劣等货？</a></p>
<blockquote>
<p>国产装备制造业机械厂里有个工艺技能，叫“照配”。意思就是配件加工时加工错了不要紧，一切都可以配。<br />
举例说。这个部件上按照图纸应该加工十对直径20的销孔，上下半分开加工。上半十个加工没有问题，下半因为马虎大意上了直径25的绞刀，干错了一个销孔。问题不大，把上半对应的那个销孔扩大到直径25，另外照配一个直径25的销子。装配时这个25的销子和另外9个20的销子一起装，装上就行。<br />
这就叫照配。又比如一根双头螺栓，两头螺纹长度要求是200长，结果发现手头这跟金属材料有点短，一头干了200，另一头长度只剩下160了。但是这根料弃之不用又可惜。那咋办?按照设计两头各有一个40厚的垫片，然后加上螺母。那么把其中一个垫片的厚度削减到5吧。然后误差还剩下5。嗯，算一下螺纹有效长度，剩下的5的误差不耽误和螺母把紧，就这么用吧。<br />
这也叫照配。又比如，这个零部件的金属材质设计要求是15cr2mo1，但是你现在没有现成材质，仓库里倒是有15cr1mo1v的材料，虽然和图纸要求不一样，但是无所谓，一样能代替，就这么用了吧。<br />
这也是一种照配。照配这个技能你在机械专业任何一本教科书上都找不到，是一个非常牛逼的技能，简直百分之八十（甚至可能更多）尺寸错误应该报废的零部件你都可以用这招把问题解决。尽管机械专业课堂上公差配合课程第一课就在强调“标准化”“互换性”，但，那又有什么关系?老板喜欢就行呗，省时省力又省钱啊。<br />
《那年那兔那些事》漫画里面有个段子说美国工程师帮中国改造两架型号一样的战斗机，发现明明同一型号的部件上的零件拆下来后居然往另一台飞机的部件上装不上，因此困惑不已。这事历史上真有假有不知道，但是这种故事发生并不奇怪。<br />
那么照配这个技能是和谁学的呢?答：苏联老师。<br />
据说苏联老师这技能就来自于战争期间的军工生产。二战时期前线非常吃紧，后方的拖拉机厂拼命生产坦克和汽车供应前线。但是生产谁还没有失误的时候?这零部件造错了?配就完事了，一切以及时供应上前线为核心，武器能装配上就行，赶紧开到前线去，反正也不指望这玩意能回来了……然后发现，这虽然违背了机械制造的标准化原则，但是省时省力又省钱啊。能用就行呗，管啥设计要求和质量?<br />
至于“粗制滥造”的指控?乐，军工产品在战场不就是消耗品吗，谁还指望这玩意能活多久似的，那还要那么长的设计寿命干啥?<br />
所以苏联老师就能设计出诸如米格29这种前线战斗机之类的产品，设计思想就是这类东西定位就是前线消耗品，只要空中格斗机动性能好就行，别的啥的人机工程和使用寿命之类的……在乎那些干啥?主打一个能装上，能用，能动，能省钱省时省精力就行了（乐）<br />
于是伴随着着156计划，苏联老师的这种思想以及照配之类的技术也就传授给了中国徒弟，然后丫的一直传承到了现在。<br />
如果你把这种制造思想指导下生产出的产品评价为粗制滥造，我觉得问题不算大。</p>
</blockquote>
<p>反正能交差就行。我觉得AI编程，可能就需要长时间去「照配」一切了。而工业化，组织化，体系化，标准化的威力，我想不必多说。</p>
<p>有了AI，人们做啥事都可以一键直达了，不需要去思考，不需要去为了中间步骤搭桥，可能以后人们慢慢的不会再发明 library和一些 design pattern 了。毕竟AI 啥都懂，能识别很多人类察觉不到的 pattern。</p>
<p>AI is one framework to rule all frameworks. 王者之戒，统御9戒</p>
<p>我赶紧向AI问，人类历史有哪些著名的 byproduct 比原来的 product 更重要？它给我胡吹了一堆，最著名的，本来是研究葡萄球菌的，然后搞出来盘尼西林。我觉得这是西医摆脱巫医的质变；当然还有 ARPANET，本来是拿来扛核打击的，结果变成互联网；塑料，本来是拿来代替一种虫胶清漆，结果引发材料学革命；</p>
<p>我大概知道一个冷门的，EUV光刻机。本来是NIF玩激光点火测试核聚变申请着玩没用的专利，交给 Intel 套现的。Intel 拿着也没用就卖给了 ASML台积电。而 NIF 其实就是个幌子项目，说是研究核聚变，实际上是拿来测试激光武器的。所谓我能对准原子核，也能对准你在外太空的导弹。</p>
<p>试想一下，如果交给 AI 来做这些事，可能就完成了平庸的任务了事。压根不会多想。</p>
<p>而且现在AI训练本身就有问题，它不太会拒绝你，它的神经网络是靠「迎合」来打分的。它不会说不知道，它只会问你 would you like to know more 来诱导消费更多的token，而不是回头看这个过程有什么有价值的东西。</p>
<p>有价值？有价值的前提是你有个baseline，你知道什么东西你不知道。但是AI又是全能全知的，它不知道自己不知道，它也不知道你不知道。</p>
<p>人类把折腾规律这一使命交给AI，人类也就失去了重大能力——命名权。</p>
<p>命名权有多重要呢？“苍颉作书，而天雨粟，鬼夜哭”。这一点在藏区作为传统被保留了下来。<a href="https://blog.est.im/201906/stderr-003">藏区的鬼神都拥有所谓的命根子</a>。命根子有几种呢？一般分为：名字，种子字等。</p>
<p>也就是说，正确喊出鬼神的名字，你就抓住了鬼神的命根子。翻译一下这句话，你把试题的出题类型正确识别了，题目也就解决了一大半。</p>
<p>人类在蛮荒时代，面对社会、大自然的无知，天生对不确定性和后果有恐惧。起名字是一件神圣，专业和高深的艺术，在汉地其实一直由祭祀阶层以「诗书传家」的方式保留到宋代，也就是造纸术发明打破了这一切。西方也一样。对人性和行为规范的定义权，被教会牢牢控制，一直到 古腾堡 Gutenberg 才打破。说起来也搞笑，东方是拿来印佛经，打破了文化阶级桎梏，西方是拿来印赎罪券，造成进天堂通货膨胀 🤣 这似乎也算重大 by-product了。</p>
<p>说远了。现在是 00:00，我想我应该总结下，AI 承包过程，必将架空人类最宝贵的过程经验。对下面发生了什么事，不仅不能察觉，连命名、定义的能力都会失去。人们以前很喜欢说 paradigm shift，我想这次，恐怕是 no paradigm left to shift。硅基的 token embeddings 人们看不懂啊。</p>
<p>所以啊，趁着还可以，多看 reasoning model 的 thought process，多思考。</p></p>
            <div class="card-subtext muted-text">
              <p>Posted <time datetime="2026-01-18T23:17:00+08:00">2026-01-18</time></p>
<p>stderr</p>            </div>
          </article>
        </div>


        <!-- new article -->
        <div class="card blog-card">
          <article class="card-body">
            <a href="/2026/stderr-02"  rel="bookmark" >
              <h2 class="card-title">The Seal Manifesto: Against the Ephemeral</h2>
            </a>
            <p class="card-text"><h2>The Seal Manifesto: Against the Ephemeral</h2>
<h3>I. The End of the Scroll</h3>
<p>For a decade, we have lived in the <strong>Age of the Vapor</strong>. We post into the void, chasing a heartbeat of attention that vanishes by morning. Our thoughts are rented to servers we don't own, managed by algorithms that don't care, and deleted as easily as they were typed.</p>
<p>We have traded <strong>Legacy</strong> for <strong>Latency</strong>.</p>
<h3>II. The Inscription</h3>
<p><strong>Seal</strong> is the end of the "Post." We do not "post"; we <strong>Inscribe</strong>.<br />
When you write here, you are not just making noise; you are adding a verse to your own personal canon. Every word is written to your local disk first. Every thought is signed with your own key.</p>
<p>Once it is <strong>Sealed</strong>, it is yours. It is a piece of history that no corporation can "un-write."</p>
<h3>III. The Weight of Words</h3>
<p>If a thought isn't worth keeping for a century, is it worth saying today?<br />
By treating microblogging like <strong>Scripture</strong>, we return gravity to the conversation. We replace the "Infinite Scroll" with the <strong>Permanent Record</strong>. We don't build feeds; we build <strong>Codexes</strong>.</p>
<h3>IV. The Courier, Not the Master</h3>
<p>Your data lives with you. Our service is merely the <strong>Courier</strong>—the mailer that carries your sealed verses into the atmosphere of the world. We cannot change what you have said. We cannot hide your history. We are the pipe; you are the source.</p>
<h3>V. Witness the Truth</h3>
<p>We believe in a social web where:</p>
<ul>
<li><strong>Ownership</strong> is local.</li>
<li><strong>History</strong> is immutable.</li>
<li><strong>Truth</strong> is signed.</li>
</ul>
<p><strong>Stop scrolling. Start Inscribing.</strong> </p>
<p><strong>Seal your legacy.</strong></p>
<hr />
<p>2012年，在懵逼之中写下了《<a href="https://blog.est.im/post/33020945266">我的信息危机</a>》，当年激发了些许讨论。</p>
<p>也正是那一年，Hinton 带着大弟子 Alex，Ilya，去 ILSVRC 踢馆拔得头筹，这场年度比赛背后是ImageNet，李飞飞趴了几千万张Flickr照片+tag，找三哥在 Mechanical Turk 挨个标成题库去考验各种古法编程手搓的分类器。</p>
<p>AlexNet靠两张NVIDIA GTX 580 3GB显卡，用224×224分辨率打败有史以来所有选手，在比赛中大幅度领先，一举成名。这场对全世界，全人类，全历史造成的震荡一直持续到今天。</p>
<p>当年我写到，输入越来越多，输出越来越少；过多信息时效化；碎片化；信噪比极低，这些问题似乎在AI时代……居然引刃而解了？</p>
<p>我渴望一个SNS，隔绝与hivemind的各种hype，又能自洽，这一点可能还需努力，于是就有了这篇 manifesto。</p></p>
            <div class="card-subtext muted-text">
              <p>Posted <time datetime="2026-01-17T13:45:00+08:00">2026-01-17</time></p>
<p>stderr</p>            </div>
          </article>
        </div>


        <!-- new article -->
        <div class="card blog-card">
          <article class="card-body">
            <a href="/2026/stdout-04"  rel="bookmark" >
              <h2 class="card-title">python版的mtr(traceroute for macOS)</h2>
            </a>
            <p class="card-text"><p>首先，我讨厌编译，我喜欢二进制，直到昨天我惊讶的发现macOS上一个 <code>yes</code> 命令都是接近100KB的大小。homebrew 一大坨东西还不一定每次都成功。</p>
<p>说起编译，这几天读到一些关于软件法律方面的风险。zhihu说如果你的工具的不针对“特定用途”，那么就可以用一定免责的说辞，但是如果你提供下载只能拿来恰好做某一件特别具体的事，那么工具的提供者就有连带责任。我想这也是为啥大部分开源软件都是提供源码吧。我这代码又不能直接用，开源是为了研究技术。你自己编译之后拿来敲不对劲的命令那是用户自己的选择了。</p>
<p>那么回到主题， <code>mtr</code> 作为居家旅行必备网络工具，它只提供源码分发。9年前研究过，用python写了demo，但是终究不是太成熟，现在有 AI ，几句话就完成了</p>
<p><a href="https://github.com/est/trpy">https://github.com/est/trpy</a></p>
<p>使用方法是 <code>sudo python3 cli.py jd.com</code> 这样。 <code>-6</code> 可以强制使用 IPv6，<code>-c1</code> 可以每一跳只probe一次并退出。</p>
<p>过程中反复折腾的，居然是最后一个 hop 重复显示，和丢失的问题。没想到AI也犯糊涂。</p>
<p>不过需要sudo还是很蛋痛。有一些折衷的办法比如去读 <code>traceroute -d</code>， <code>mtr</code> 或者 iproute2 的debug输出，有空再折腾。</p>
<p>期间遇到n次无法编辑文件的情况，估计AI输出乱了。还有不知道为什么，Google Antigravity每次写完代码就打 <code>Aurora</code> 几个字到末尾。</p>
<p>现在基本框架有了，下一步支持点什么插件好呢。</p></p>
            <div class="card-subtext muted-text">
              <p>Posted <time datetime="2026-01-16T00:10:00+08:00">2026-01-16</time></p>
<p>stdout</p>            </div>
          </article>
        </div>


        <!-- new article -->
        <div class="card blog-card">
          <article class="card-body">
            <a href="/2026/stdout-03"  rel="bookmark" >
              <h2 class="card-title">尝试让AI手搓个TTF格式生成器</h2>
            </a>
            <p class="card-text"><p>一个奇怪的需求：如何在浏览器判断一个字体是否支持某个字符？</p>
<p>（原始需求是：遇到一些字符渲染错位问题，看起来是字体不支持，fallback 到别的去了。）</p>
<p>想到的方法是：用canvas渲染看宽度。但因为这个 fallback机制，所以更好的办法是拿一个已知的特殊字体去比对，如果fallback了说明不支持。</p>
<p>那么问题来了，这个 fallback font 你不可能下载一个包含所有字符的，那样体积会很大，所以最好是按需生成一个，只包含一个字符，用来比对。那么这个问题就转换成了：如何在浏览器js里动态生成一个 .ttf 格式的字体文件，只包含一个字符？</p>
<p>这里不考虑 woff woff2，因为前者已经过时了后者比 ttf 更复杂。</p>
<p>一开始以为很easy，让 ChatGPT搓，打开浏览器就懵逼 </p>
<pre><code>OTS parsing error: bad table directory searchRange
bad table directory entrySelector
bad table directory rangeShift
Invalid table tag: 0x66000000
f\x00\x00\x00: invalid table offset
</code></pre>
<p>感觉事情没那么简单。让Antigravity搓，它把我免费额度烧光了也没搓出个所以然</p>
<p>其中一个小插曲是，css里允许对单独一个字符设置 <code>font-family</code>，但是因为这个 .ttf 是动态生成的，所以需要动态生成这个CSS的声明，所以在生成 .ttf 之后需要类似这样的代码：</p>
<pre><code>document.head.insertAdjacentHTML(&quot;beforeend&quot;, `
&lt;style&gt;
@font-face {
  font-family: GhostRaw;
  src: url(${url});
  unicode-range: U+2603;
}
body { font-family: GhostRaw, system-ui; }
&lt;/style&gt;
`);
</code></pre>
<p>注意这个是在 html 里的 js 里的 template string 里的 css。antigravity改这一块出现了好多次 error，我猜是AI输出格式嵌套格式本来就容易出错，这里引用和转义太复杂以至于 agent 直接看不懂output了。哈哈</p>
<p>因为没额度了，所以换国产免费的 Trae。Trae 比antigravity更笨，但是也努力。js搓不动，就开始换写 .py 去验证。搞到最后搞出来一堆测试文件</p>
<p>check_maxp.py<br />
check_validation.py<br />
generate_minimal_ttf.py<br />
generate_proper_ttf.py<br />
generate_simple_zero_width_font.py<br />
generate_ttf.js<br />
generate_zero_width_font.py<br />
generated_font.ttf<br />
generated_font.ttx<br />
get_base64.js<br />
minimal_font_generator.py<br />
modify_existing_font.py<br />
simple_font_generator.py<br />
validate_ttf.py<br />
validate.js<br />
working_font_generator.py<br />
zero_width_font.ttf<br />
zero-width.ttf</p>
<p>这样几回合下来，直接搓超出上下文了，最后直接罢工，出现</p>
<blockquote>
<p>Output is too long, please enter 'Continue' to get more.</p>
</blockquote>
<p>而且你点了 continue 它思索半天还是出现这句话。上下文是彻底爆了。</p>
<p>正向构造一个 .ttf 很难，AI还很聪明的想到了：</p>
<blockquote>
<p>我将使用一个更简单的方法，直接使用一个现有的基础字体文件，然后修改它的字符映射。让我检查一下是否有任何基础 TTF 文件可用。我将使用 Google Fonts 中的一个非常简单的字体作为基础。</p>
</blockquote>
<p>最后还是失败了。于是我就去搜索引擎找到了这个：</p>
<p><a href="https://pomax.github.io/Minimal-font-generator/">https://pomax.github.io/Minimal-font-generator/</a></p>
<blockquote>
<p>dynamically generated bespoke font that encodes that character as a zero-width glyph<br />
in the PDF.js project, where a PDF file may have fonts embedded for rendering text with, but no way to tell whether an extracted font has actually finished loading.</p>
</blockquote>
<p>和我想到一块去了。还是人类老哥牛逼，2012-01-14号就把这个方案搓出来了，距今刚好整整14年。</p>
<p>AI就像一个培训班出身的，对背题能过的任务能很快完成，对于这种考验细节的冷门任务，还是难。</p></p>
            <div class="card-subtext muted-text">
              <p>Posted <time datetime="2026-01-14T22:48:00+08:00">2026-01-14</time></p>
<p>stdout</p>            </div>
          </article>
        </div>


        <!-- new article -->
        <div class="card blog-card">
          <article class="card-body">
            <a href="/2026/stdout-02"  rel="bookmark" >
              <h2 class="card-title">精打细算VPS扫除</h2>
            </a>
            <p class="card-text"><p>2022年买的VPS一直没怎么管，今天想跑点东西发现大户 warp-cli 真是吃资源啊。果断删掉</p>
<p>公司的服务器都是SA管理，自己的一般很少去折腾，这次也是闲的，好奇系统里杂七杂八都是啥玩意儿，挨个找AI审问一遍</p>
<p><code>systemctl list-units --type=service --state=running</code></p>
<ul>
<li><code>blk-availability</code>  <code>udisks2</code>  插拔优盘的</li>
<li><code>fwupd</code>  固件更新</li>
<li><code>ModemManager</code> </li>
<li><code>multipathd</code> <code>open-iscsi</code> <code>iscsid</code>  存储用的</li>
<li><code>packagekit</code> GUI包管理器</li>
<li><code>polkit</code>  GUI 策略kit</li>
<li><code>snapd</code> <code>snapd.apparmor</code> <code>snapd.autoimport</code>  GUI里的 App store</li>
<li><code>lvm2-monitor</code></li>
<li><code>upower</code> <code>thermald</code> 电源和温度传感器</li>
<li><code>cloud-init*</code> <code>cloud-config*</code> 云配置器</li>
<li><code>apport*</code> Crash reporting</li>
</ul>
<p>这些都没用！直接 <code>sudo systemctl disable --now XXX</code> 禁用</p>
<p>其中 snapd 直接 <code>sudo apt purge snapd</code> 斩草除根！</p>
<p>最后看一下  <code>free -h</code> <code>used=110Mi</code> 感觉好多了。</p>
<p>顺便把文件也清理下 <code>sudo journalctl --vacuum-size=500M</code>，发现比较大，编辑 <code>vi /etc/systemd/journald.conf</code></p>
<pre><code>[Journal]
SystemMaxUse=500M
</code></pre>
<p>然后 <code>sudo systemctl restart systemd-journald</code></p>
<p>为什么要整理VPS？因为大善人Cloudflare 和 Vercel 都有 request buffering 导致一个 hobby project 做不下去了</p></p>
            <div class="card-subtext muted-text">
              <p>Posted <time datetime="2026-01-13T22:30:00+08:00">2026-01-13</time></p>
<p>stdout</p>            </div>
          </article>
        </div>


        <!-- new article -->
        <div class="card blog-card">
          <article class="card-body">
            <a href="/2026/stdout-01"  rel="bookmark" >
              <h2 class="card-title">I made a paste service</h2>
            </a>
            <p class="card-text"><p>I've been busy vibe coding a paste service. Sharing content has been painful these days and I always have some snippets or images to share with my friends. </p>
<p>The service is up and running in publick hosted <code>$URL = https://p.est.im</code></p>
<p>It's running on a free tier Cloudflare Worker with everything stored in D1.</p>
<p>To upload a paste is easy, just <code>curl -T /path/myfile.txt $URL</code>. A random paste ID would be generated and returned.</p>
<p>Or you can pipe some logs like <code>cmd | curl -T - $URL</code>. If you take a close look at the headers you can even find a delete token</p>
<p>Hopefully no major spam nor abuse happen to this service. I did try hardwork to prevent them best to my knowledge, like </p>
<ul>
<li>Content-Security-Policy is very strict</li>
<li>Anti hot-linking using Sec-Fetch-Site</li>
</ul>
<p>The source code is available at <a href="https://github.com/est/p.est.im">https://github.com/est/p.est.im</a></p>
<p>If you have any better ideas please let me know 😎</p></p>
            <div class="card-subtext muted-text">
              <p>Posted <time datetime="2026-01-10T12:36:00+08:00">2026-01-10</time></p>
<p>stdout</p>            </div>
          </article>
        </div>


        <!-- new article -->
        <div class="card blog-card">
          <article class="card-body">
            <a href="/2026/stdin-01"  rel="bookmark" >
              <h2 class="card-title">「负面」</h2>
            </a>
            <p class="card-text"><p><a href="https://news.ycombinator.com/item?id=46512881">Hacker News 超过65%的回复是负面</a></p>
<p>评论一大堆质疑的。但是这么多质疑本身也是证明大部分回复都是……负面。这算是老问题了，我一直觉得NLP似乎很喜欢做 sentiment analysis。也写过一篇<a href="https://blog.est.im/2023/stderr-07">为什么网上喷子那么多，戾气那么大？</a></p>
<p>回到最根本的点上，正面负面，这玩意不是很主观的吗？怎么能个 classifier 就能区分得那么清楚呢？</p>
<p>刚要睡觉，结合之前 <a href="https://blog.est.im/2025/stdin-12">LSTM 的发明人通过数学公式定义什么是「美」</a>，突然有个想法。</p>
<p>更好的分类是—— ugly or not。这里的 ugly 就是「出丑」表示不对劲 的意思。</p>
<p>有个底层逻辑是，如果遇到符合预期，正常的东西，人们是不会费时间写字儿赞美，认同，表扬的。但是遇到 ugly 的需要额外费劲解释的，多半会投入精力去辨析。</p>
<p>容易接受的东西不一定是对的，但是接受度高的东西就是smooth的。大脑皮层褶皱被熨平那种丝滑感，即便陈述是错的，也可以欣然接受。毕竟「押韵的就是有道理的」</p>
<p>如果需要大费周章去辨析的东西，那么它就是有问题的，<a href="https://blog.est.im/archives/2993">something wrong</a>，那就是「负面」——所谓 negativity bias，即人类在感知、记忆、判断和决策中，对负面信息（危险、错误、丑陋、不一致）比正面信息更敏感、更容易记住、更倾向于反应。</p>
<p>新生婴儿生下来学会的第一句话——啼哭，就是大脑对环境剧烈改变这个强烈信号刺激做出的本能反应。<a href="https://blog.est.im/2025/stderr-03">今年Q2</a>我琢磨的。但是我没想明白人又是怎么学会 笑 的。哭 和 笑 可以说是在掌握0语言基础上，对世界的表征最大可能做出的二元化近似了。人类以后一切的情感和语言可以看成从这对立的两面发展而来。但是又很矛盾的一点是，人脑又极其擅长去做 pattern matching。或许 哭 是模式变得 ugly 之后的无力感？</p>
<p>又或，人脑是被迫陷入经典的“五等悲痛”？ Denial - Anger - Bargaining - Depression - Acceptance？</p>
<p>带着深深的困意，这些lovely, dark and deep的东西就有时间再「入木」了。睡觉先。</p>
<hr />
<p>第二天补充：有办法解决haters gonna hate 问题。下面的主意来自ChatGPT，有问题找山姆奥特曼</p>
<p>先定性：为什么会有 haters（叙事层面的现实）</p>
<p>从前面聊的 ugly / negativity bias 这条线看，其实可以一句话概括：Hate 本身就是“异常被注意到”的副产品，而不是失败的证据。所以解决hater的核心目标不是：让负面消失，而是：让负面失去叙事杀伤力。</p>
<p>所以最低成本解法：去人格化（de-personalization），这是 “haters gonna hate” 的底层逻辑。技术上说就是 不反驳具体内容，不承认“你说的是我”，把 hate 归类为自然现象。从修辞上把攻击降级为背景噪音。</p>
<p>进一步的解，归因转移（Attribution Shift）。不否认 hate，而是改变 hate 的来源解释。把 有人骂你 → 因为你有问题。改为 有人骂你 → 因为你在挑战旧秩序，你在改变既得利益，你做了“不可忽视的事”。把 hate 从 负面反馈 变成 变革信号。</p>
<p>高级一点，把 hate 纳入主叙事。不是回避 hate，而是提前在故事里给它一个位置。比如：我们知道会有人反对；反对本身是可预测的；反对并不改变核心方向。这一点在科技公司 创业者里常见。比如 Some people will say this can’t be done。让 hate 不再是意外，而是剧情的一部分。</p>
<p>终极手段，把 hate 变成 身份确认器。核心是如果所有人都满意，那你一定什么都没做。于是被谁骂反而定义了你是谁。hate 成为 “我们是谁 / 他们不是谁” 的分界线。比如典型话术 “If everyone likes it, it’s probably not for us.”，“We’re not trying to be universally loved.”，“This isn’t for everyone — and that’s intentional.”。这一步，hate 反而增强了品牌/立场的清晰度。</p>
<p>in a perfect world，做正确的事，是产生价值。不管是写代码、写文章、做产品，还是推进一件现实中的事，本质上都是把有限的注意力、时间和精力，投入到一个能持续产出正价值的方向上。价值可能很小，但只要是正的，就会慢慢累积。</p>
<p>而 hater 的问题不在于“不认同”，而在于产生负价值。他们并不只是表达意见，而是制造干扰：打断节奏、劫持注意力、迫使你进入解释模式。你不得不停下正在做的事，花额外的精力去澄清、辩解、填补认知空洞。哪怕最后你“说清楚了”，系统层面仍然是亏损的——原本可以继续前进的那段时间，已经被消耗掉了。</p>
<p>这也是为什么很多负面并不值得回应。不是因为它们“错误”，而是因为回应本身的期望值为负。真正昂贵的从来不是被骂，而是被迫暂停创造，去处理本不该进入主流程的噪声。</p>
<p>从这个角度看，hater 不是一种观点，而是一中断；不是反馈机制，而是外部性。而一个正常运转的系统，首要任务永远是——把注意力留给能产生价值的事情。</p></p>
            <div class="card-subtext muted-text">
              <p>Posted <time datetime="2026-01-07T00:08:00+08:00">2026-01-07</time></p>
<p>stdin</p>            </div>
          </article>
        </div>


        <!-- new article -->
        <div class="card blog-card">
          <article class="card-body">
            <a href="/2026/stderr-01"  rel="bookmark" >
              <h2 class="card-title">LLM的弱点——不能很好的讲笑话？</h2>
            </a>
            <p class="card-text"><p>元旦节长途旅行，无聊，我问娃，AI的弱点是什么？答：没有嗅觉，这个的确是物理限制，我之前吹的。哈哈哈。AI has no taste 🤣</p>
<p>这一路为了打法无聊时光，下载安装了个豆包闲聊。娃很喜欢猜历史人物。我发现一个规律，豆包似乎在缩小3、4次范围之后，就会进入 “你想的是不是XXX” 这种点菜名儿模式，而不是想办法进一步缩小范围。</p>
<p>这种模式如果是猜常见人物，那么特别准。如果是猜冷门、模糊的的，就容易 miss。</p>
<p>AI这种 hit or miss，让我不禁联系到不知道哪里看到过一个大佬的说法，现阶段LLM有个弱点，训练的时候给 next token “回答正确” 的单一结果给的权重太高，比如让AI讲一个 joke，它便老是翻来覆去讲那一个最擅长最经典的，就像是背题背出幻觉了。</p>
<p>不能很好的讲笑话，难道是LLM的终极弱点？</p>
<p>让真人马上讲个笑话，如果一时半会儿想不到好的joke，会随便找个现成的凑数。AI我试了 gemini，chatgpt，deepseek都很烂。不好笑。或许是有的笑话是英语硬翻译过来丢了东西，也可能是我没接触到更好的AI，或者我 prompt 不会写，甚至SOTA已经解决了这个问题？</p>
<p>如果没解决，我们是不是可以说，LLM往往对于有明确答案的东西能一发入魂；对于有多个能接受答案的东西明显变化度不足，甚至给个很差的答案。</p>
<p>我也不知道这是为什么。但是反之 LLM 可以很到位的解释 joke 的笑点在哪里，它不能搜集这些经典笑话然后下一次需要用到的时候复述一遍。或许 transformer 就不是拿来干这个的，毕竟它是 decoder-only的。是不是应该交给RAG做这个事？</p>
<p>我感觉现在的 reasoning 模型把这个问题变得更严重了。推理的时候想得太多。 Reinforcement Learning from Verifiable Rewards (RLVR) 是不是导致轻松愉快随便讲个笑话变得更痛苦严肃？</p>
<p>或许 joke 这事本来就是逆智的东西。弱智吧的笑话是最让我想笑的。AI聪明过头了找不到好笑的，随便打发个回答。</p>
<p>有研究甚至说 <a href="https://arxiv.org/abs/2509.12158">AI 压根不懂 pun</a>。比如 </p>
<blockquote>
<p>I used to be a comedian, but my life became a joke</p>
</blockquote>
<p>把最后的 joke 换成 chaotic，AI依然觉得好笑。哈哈，这是词向量近似了吧 🤣</p>
<p>还有人说AI讲不好笑话是因为，<a href="https://danfabulich.medium.com/llms-tell-bad-jokes-because-they-avoid-surprises-7f111aac4f96">AI会刻意避免意外、惊喜行为</a>。作者说笑话的本质是一个不对劲的东西，然后回头看有搞怪的地方——a joke is surprising, but inevitable in hindsight。如果回头看没看明白，那么就是个烂梗。如果一个人看了太多梗，那么TA笑点就很高，作者以此推断出，没有“最牛笑话”。笑话总是在没见过的人眼里最好笑。AI的训练就陷入怪圈：训练得越多，什么笑话都见过了，越不好笑，笑点就越奇怪。这个问题不是加大训练力度能解决的。作者同时推断，这也是AI没法编一个好的故事情节的原因。</p>
<p>对于这个说法，<a href="https://news.ycombinator.com/item?id=44932170">HN有评论</a> 说 Daniel Dennett 有本讲《Inside Jokes》书，幽默是心灵的逆向工程。</p>
<blockquote>
<p>humor depends on errors in reasoning and the punchline causes you to reevaluate your reasoning and discover your error. Humor evolved to be enjoyable to encourage the discovery of errors.</p>
</blockquote>
<p>这个说法感觉有点特别倾向老外式的 joke。比如 “程序员为什么老是搞混万圣节和圣诞节？因为 Oct 31 == Dec 25” 这类，我感觉更多的是 幽默。国内的笑话我感觉更无限逼近“地狱笑话”那种段子，要么是看别人倒霉，或者是屎尿系列的 butt joke 。</p>
<hr />
<p>除了讲笑话的问题，还有最老生常谈的LLM幻觉问题。猜成语我想了个冷门的「投杼逾墙」，AI懵逼。btw 这个成语也是 也是卢格杜努姆的奥古斯丁 这个up主之前某一期爆的典。</p>
<p>然后又看到 <a href="https://mp.weixin.qq.com/s/k147AyWj01W-V7IpkV0g2A">Steve Yegge 的访谈</a>。的确现在 agent 生产会导致人和人的差距越来越大。我在想LLM似乎就很适合编程这种有规律可循，答案又很确定，很多写法都是 there should be one– and preferably only one –obvious way to do it，太适合 LLM 了。</p>
<p>新年第一天，杂七杂八胡思乱想一篇。看了眼已经 01:37 了 😂</p></p>
            <div class="card-subtext muted-text">
              <p>Posted <time datetime="2026-01-01T23:57:00+08:00">2026-01-01</time></p>
<p>stderr</p>            </div>
          </article>
        </div>


        <!-- new article -->
        <div class="card blog-card">
          <article class="card-body">
            <a href="/2025/stderr-14"  rel="bookmark" >
              <h2 class="card-title">礼教的核心议题是——认爹</h2>
            </a>
            <p class="card-text"><p>一直关注 卢格杜努姆的奥古斯丁 这个up主。今天刷到他<a href="https://www.bilibili.com/video/BV1PFmGBfEfE?t=380.3">最新的一期</a>，讲到Pope最近去土耳其伊斯坦布尔访问的事。历史上基督教分裂成两大教派 天主教 vs 东正教，天主教在罗马梵蒂冈，东正教圣城便是君士坦丁堡。最新当选教皇的那个美国人在和大牧首会见，颂念《尼西亚信经》的时候，没有念出 Filioque。于是作者又花力气解释了这个 Filioque，也就是和子问题，两大「正统」教派之间最核心的分歧。</p>
<p>简单的说，基督教流派里，最大公约数有7次大公会议，第一次 尼西亚大工会，由罗马皇帝君士坦丁一世召开，大会主要成果是认定：儿子和老汉是一回事。不认同大会决定的分裂出来 阿利乌斯派、聂斯脱里派。《大秦景教流行中国碑》里那个 景教，就属于支持聂斯脱里的基督二性论的。</p>
<p>第二次大工会：君士坦丁堡公会议，主要解决第一次大会的遗留问题：他爷俩为啥这么屌？</p>
<ul>
<li>君堡☦️的人觉得：圣灵/圣神，是主及赋予生命者，因为老汉比较屌。qui ex Patre procedit</li>
<li>罗马✝️的人觉得：圣灵/圣神，是主及赋予生命者，因为老汉及儿子比较屌。qui ex Patre, <em>Filioque</em> procedit</li>
</ul>
<p>其实说来说去，为毛这么纠结，还不是因为叙利亚中东蛮子里出了个神人在君堡附近干了番大事业，肉体成圣了。他的地位怎么趋附到旧约耶和华身上才符合时代需要？</p>
<p>跟朋友说了下这个事，他说不要去掺和宗教的事。</p>
<p>我说：嘉靖跟文官闹了一辈子的别扭，原因就是如何称呼他爹。朋友被逗乐了，表示非常对 🤣 由此可以得到，无论东西方，如何认爹都是礼教的核心议题啊。</p>
<p>宋英宗也一样。被抱来抱去，名分模糊，最后整个朝廷都在替他补一份“我究竟是谁儿子”的说明书。</p>
<p>又想起，孔子搞这些也是一把好手，他的成名作就是去找他野爹的坟头。然后他这个殷商贵族后裔，居然跑去贴靠周礼，认爹认出路径依赖了。把“认爹”从血缘提升为伦理，从私人问题升级为公共秩序。</p>
<p>东方所谓君臣父子，皇帝既是“天子”（天之子），又是“君父”（民之父母），兼具神圣性与宗法性；教会与王权争夺地位，无非都最终诉诸“终极父亲”——上帝。</p>
<p>为什么东西方礼教对认爹这么执着？认爹其实就是对权威源头、统治合法性或意义根基的追溯与承认。</p>
<p>为啥不是认娘？娘和子女的关系是天生不可分裂的。我甚至极端的觉得：人类发明文字，就是当爹的用来跟踪自己的财产，以及标注继承人需要。这样财富才能通过指定的名字传承。</p>
<p>精神恍惚中，我甚至怀疑，屈折语里这么强调属格，会不会出于确定屁股位置的实际需求？古希腊和罗马语言学家认为，名词的“主格”是正直的，其他的格（如宾格、属格）都是从主格“倾斜”（Decline）出去的，所以叫“变格”。搞这么抽象的三位一体学说，无非是用什么位格的词藻来修饰耶大爷那些神迹更加有高级感的的工程问题。这爷俩是一人还是两人？动词（procedit）都用单数了，所以神必然都是单例。</p></p>
            <div class="card-subtext muted-text">
              <p>Posted <time datetime="2025-12-29T20:13:00+08:00">2025-12-29</time></p>
<p>stderr</p>            </div>
          </article>
        </div>


        <!-- new article -->
        <div class="card blog-card">
          <article class="card-body">
            <a href="/2025/stderr-13"  rel="bookmark" >
              <h2 class="card-title">“缸中之脑” 被我破解了</h2>
            </a>
            <p class="card-text"><p>最近epic送了《Hogwards Legacy》我打通关了，作为原著党，十分着迷这部小时候的经典，在美轮美奂的想象世界骑扫帚，看冥想盆里剧情故事，都十分有趣。</p>
<p>昨天晚上加班到很晚，晚饭吃得玩，睡得更晚，肚子有点涨，早上做了非常奇怪的梦，一直吃东西，然后不小心把坐牙给弄掉出来了。感觉嘴里一阵穿堂风：</p>
<p><img alt="" src="/images/2025/stderr-12-01.jpg" /></p>
<p><em>图片由ChatGPT生成，十分还原。梦里的这颗牙齿就是带着蓝色静脉和红色动脉线条。奇怪吧</em></p>
<p>出于本能，我赶紧咬合了一下，确认是不是真的掉牙齿了。结果一咬发现坐牙都还在。大脑瞬间崩溃，bia～ji 一下给我整醒了。</p>
<p>一看时间：06:40 tnnd。感觉没睡够，于是倒头又想重新入睡。大脑里突然闪现出 哈利波特 通过冥想盆看别人故事VR，又突然想到以前的经典电影《黑客帝国》，越想越睡不着。脑子里绷出来一件事：</p>
<p>缸中之脑 必然能被破解？</p>
<p>「<a href="https://plato.stanford.edu/archives/sum2006/entries/brain-vat/">brains in a vat</a>」是一个经典科幻设定。它说：</p>
<blockquote>
<p>也许你现在并不是真正的身体在现实世界中感知，而只是 一颗漂浮在营养液体缸中的大脑，它通过超级计算机产生的电信号获得和正常人一样的感觉体验。如果这个假设成立，那么你所有关于外部世界的经验与信念都可能是假的。</p>
</blockquote>
<p>这个说法被 Putnam 批判了：</p>
<blockquote>
<p>如果你真的是一颗缸中之脑，那么你的词语（例如“树”）就 不可能指向现实中的树，因为你没有与真实树发生因果接触。那么你的语言和思想内容就不是我们通常理解的那些含义。所以“我是缸中之脑”这样的陈述在这种情况下并不成立其本来意义</p>
</blockquote>
<p>我觉得 Putnam 这个说法也是有问题的。大脑不是一个“被创造物”，而是一大堆肢体感官进化之后的连接网的中枢。所以大脑必然和“人”这种结构是一体的。所以我们默认，缸中之脑 这个设定上就是错的的。既然要模拟，那么这个问题的升级版就得是「缸中之躯 body in a vat」</p>
<p>那么问题来了，如果你整个身躯如同 the Matrix 那样当电池养着，感官意识生活在虚拟世界里，仅凭自己，能识别出这一点吗？</p>
<p>问了很多AI，结论都是</p>
<blockquote>
<p>被安置在另一物理层级中的完整人类系统，单靠 我思、内省、反思意识 永远无法推出“我在 vat 里”</p>
</blockquote>
<p>然而我觉得是可以的破解的。正如我那个奇怪的梦一样，很简单，如果在 the Matrix 里，你直接去跳楼，或者发生交通事故，腿断了。这个常见吧？但是你肉体的腿没断啊。这个时候 the Matrix 为了精确模拟，是不是得把你神经信号精确在创口面截断？下肢没感觉了就是断了。</p>
<p>只切断信号不行啊。肌肉还连着呢？也得去掉关联？那么一大坨肉，体重质心也得跟着模拟纠偏呢？泡在水里的角动量怎么平衡呢？嘿嘿。</p>
<p>再比如，你一拍大腿，摸摸自己的膝盖，你的肉体其实有实体的东西存在，给物理碰撞挡着了。但是你在虚拟世界里理论上应该只能摸到空气，手臂挥舞的路径需要能穿过大腿所在位置。这穿模了等于是。这么麻烦，耗费电力计算资源，还不如系统直接禁止你摸腿。</p>
<p>而且系统得“发挥创造力”模拟你走路不便的样子，虽然实际上你肉体是完整的。</p>
<p>等等种种，我感觉，这种模拟肯定会出漏子，不真实。</p>
<p>可以得出一个结论：the Matrix 里是没有后天残疾人的。回想了一下电影里打斗场景虽然多，但是的确大马路上没一个缺胳膊断腿的。</p>
<p>把一个不存在的东西模拟出来欺骗大脑容易，但是要把一个存在的东西抹去隐藏，付出的努力就复杂麻烦得多得多。就好比，把橙汁倒进水容易，但是要把橙子里的水分离出来，那可就麻烦多了。</p>
<p>我称之为《the Matrix里无🧑‍🦽轮椅》定理 </p>
<p>高级一点的说法，水里加橙汁增熵容易，但是你要模拟橙汁里没水，系统就得整体降熵。这个代价足以摧毁一切系统。</p></p>
            <div class="card-subtext muted-text">
              <p>Posted <time datetime="2025-12-26T08:52:00+08:00">2025-12-26</time></p>
<p>stderr</p>            </div>
          </article>
        </div>


        <!-- new article -->
        <div class="card blog-card">
          <article class="card-body">
            <a href="/2025/stderr-12"  rel="bookmark" >
              <h2 class="card-title">程序员和普通人有什么不同之处</h2>
            </a>
            <p class="card-text"><p>很久之前看到个闲聊 <a href="https://www.v2ex.com/t/1175474">程序员相对于大部分普通人，优势在于哪里？</a>，让AI 总结一下，优势大概无非这么几点</p>
<ul>
<li>工具性能力<ul>
<li>信息检索与筛选能力更强（搜索、判断信息真假、避免诈骗）。 </li>
<li>更熟练使用计算机与互联网工具。</li>
<li>能阅读英文技术资料（至少不抗拒）。</li>
<li>更容易接触并使用新技术（如 LLM、AI 工具）。</li>
</ul>
</li>
<li>问题拆解与逻辑分析<ul>
<li>能将复杂问题拆分、定位关键变量（debug 思维、XY problem 意识）。</li>
<li>对流程、因果、边界条件更敏感。</li>
</ul>
</li>
<li>自动化<ul>
<li>面对重复性、规模化任务，倾向于用程序或工具一次性解决。</li>
<li>对“手工反复做事”容忍度低。</li>
</ul>
</li>
<li>持续学习<ul>
<li>技术更新快、面试压力大，迫使长期学习。</li>
<li>相比不少毕业后停止系统学习的群体，程序员中位数更高</li>
</ul>
</li>
</ul>
<p>当然，ChatGPT 的回答更好，我有修改和评论如下：</p>
<h3>一、把“模糊问题”拆成“可执行步骤”的能力</h3>
<p>这是程序员最核心、也最被低估的优势。面对一个模糊目标，程序员天然会问：</p>
<ul>
<li>输入是什么？</li>
<li>输出是什么？</li>
<li>中间有哪些状态？</li>
<li>失败路径是什么？</li>
</ul>
<p>这种<strong>结构化拆解</strong>能力，在现实世界里更常见的是“我只设想了一种成功路径，就有概率能成”。参考最近《勇哥说餐饮》节目里各种案例。</p>
<h2>二、对“系统”和“因果链”的直觉更强</h2>
<p>程序员每天都在和系统打交道：。状态是如何流转的？一个小改动会引发哪些连锁反应？哪里是瓶颈、哪里是单点故障？所以他们往往更擅长：</p>
<ul>
<li>看穿流程里的 隐藏规则</li>
<li>识别“这个设计迟早要出问题”的地方</li>
<li>理解现实世界里的制度、组织、流程其实也是系统</li>
</ul>
<p>很多人是“事件驱动思维”（今天发生了什么），程序员更偏向“系统驱动思维”（为什么会这样发生）。</p>
<h2>三、对“抽象”和“符号世界”的适应力</h2>
<p>程序员长期生活在一个高度抽象的世界里，变量 ≠ 现实对象，但能代表它；接口 ≠ 实现；规则写清楚，比情绪重要。这会带来几个现实优势：</p>
<ul>
<li>更容易理解复杂制度（合同、政策、金融规则）</li>
<li>更不容易被表象或话术迷惑</li>
<li>更擅长在规则允许的空间里做优化，而不是硬碰硬</li>
</ul>
<h2>四、可复制的“学习—验证—修正”闭环</h2>
<p>程序员学习的典型模式是 查文档，看源码，动手试，报错 - 修 - 再试。这是一种 快速反馈学习机制，相比之下，很多普通人的学习是：听别人讲 - 记住结论 - 很久以后才知道对不对</p>
<p>所以程序员往往对新领域不那么害怕，更相信“我可以边做边学”，对失败的心理成本更低（反正先跑不起来）</p>
<h2>五、对自动化与杠杆的敏感度</h2>
<p>程序员很早就被训练成对这类问题敏感。这个事情要重复做吗？能不能写个脚本？能不能一次性解决？这会自然转化为更懂得利用工具，放大个人产出，更早意识到“时间 ≠ 产出”的非线性关系。很多普通人是“多干点=多产出”，程序员更容易意识到“一次设计，长期复利”。</p>
<h2>六、相对理性的风险观</h2>
<p>写代码会反复教你一件事：世界不是非黑即白，边界条件比主路径更重要，“大概率正确”比“情绪确信”靠谱。这使得程序员在很多现实决策中更看概率而不是故事，更能接受不完美方案，更少沉迷“赌一次大的”</p>
<hr />
<p>我个人的见解，程序员唯一天生的优势就是逻辑流程的附加值。当你写一堆 if 之后，发现有个 else 需要补，然后往往之前考虑的东西里压根就没想到这一层会出问题。</p>
<p>换句话说，我感觉普通人看待事物都是「点」为主。提需求和验收都是各个「点」。拥有「线」或「面」思维的人少之又少。但是程序员从一开始就不得不考虑「空间」，如果你喜欢各种“设计模式”，甚至meta programming，需要考虑 configuration space，所以看待事物比普通人更广。对约束和边界的理解比普通人看得更透彻。多实践几次防御式编程（Defensive Programming），会对世界上那些事容易，哪些事复杂有更清晰的认知。</p>
<p>其他的优势感觉更多是个体差异，谈不上优势。没了。</p></p>
            <div class="card-subtext muted-text">
              <p>Posted <time datetime="2025-12-24T21:08:00+08:00">2025-12-24</time></p>
<p>stderr</p>            </div>
          </article>
        </div>

    </main>
    <nav class="pagination-nav side-padding">
<a href="/index.02.html" class="pagination-older">Older Posts &gt;</a>    </nav>


  </body>
</html>