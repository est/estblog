<!DOCTYPE html>
<html>
  <head>
    <title>LLM的弱点？ – est の 输入 输出和出入</title>
<link rel="icon" href="https://est.im/favicon.svg">
    <meta charset="utf-8" />
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta http-equiv="Content-Security-Policy" content="frame-ancestors 'self' https://disqus.com https://player.bilibili.com https://www.youtube.com;">
    <link href="https://feeds.feedburner.com/initiative" type="application/rss+xml" rel="alternate" title="est の 输入 输出和出入 RSS Feed" />

    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="LLM的弱点？" />

    <link rel="canonical" href="https://blog.est.im/" />
    <meta property="og:url" content="https://blog.est.im/">
    <meta property="og:type" content="article">
    <meta property="og:title" content="LLM的弱点？">

    <link rel="stylesheet" href="/theme/css/normalize.min.css" />
    <link rel="stylesheet" href="/theme/css/style.css" />


    <style>
      body {
        background: #ecedef url("/theme/img/ignasi_pattern_s.png") repeat;
      }
    </style>
  </head>
  <body class="single-body">
<nav class="nav-bar side-padding">
  <h1 class="nav-header"><a href="/" class="nav-text">
    est の 输入 输出和出入
  </a></h1>
  <div class="hamburger-menu">
    <button>
      <span></span>
      <span></span>
    </button>
    <ul id="menu" class="hamburger-menu-overlay">
      <li><a href="/" class="hamburger-menu-overlay-link">Home</a></li>
      <li><a href="https://feeds.feedburner.com/initiative" class="hamburger-menu-overlay-link">RSS</a></li>
      <li><a href="/about" class="hamburger-menu-overlay-link">About</a></li>
      <li><a href="/category" class="hamburger-menu-overlay-link">Category</a></li>

    </ul>
  </div>
</nav>    <main class="content side-text-padding">
<article class="post">
  <header class="post-header">
    <h2 class="post-title">LLM的弱点？</h2>
    <p class="post-date">Posted <time datetime="2025-01-01T23:57:00+08:00">2025-01-01</time> | <span>stderr</span></p>
  </header>

  
  <p>旅途中，我问孩子AI的弱点是什么，它们一口回答没有嗅觉，我之前跟它们吹的。哈哈哈。AI has no taste 🤣</p>
<p>这一路为了打法无聊时光，下载安装了个豆包闲聊。孩子很喜欢猜历史人物。我发现一个规律，豆包似乎在缩小3、4次范围之后，就会进入 “你想的是不是XXX” 这种点菜名儿模式，而不是想办法进一步缩小范围。</p>
<p>这种模式如果是猜常见人物，那么特别准。如果是猜冷门、模糊的的，就容易 miss</p>
<p>想起来不知道哪里看到过一个大佬的说法，现阶段LLM有个弱点，训练的时候给 next token “回答正确” 的单一结果给的权重太高，比如让AI讲一个 joke，它便老是翻来覆去讲那一个最擅长最经典的。就像是背题背出幻觉了。它不知道自己不知道。</p>
<p>人面对这样的问题，一时半会儿想不到好的joke，会随便找个凑数。当然，可能是我没接触到更好的AI，或许SOTA已经解决了这个问题，如果没解决，那么LLM的优点就是：对于有明确答案的东西能一发入魂；对于有多个能接受答案的东西明显变化度不足。</p>
<p>我也不知道这是为什么。LLM 可以很到位的解释 joke 的笑点在哪里，但是它却不能搜集这些经典笑话然后下一次需要用到的时候复述一遍。或许 transformer 就不是拿来干这个的，毕竟它是 decoder-only的。或许应该交给RAG做这个事？</p>
<p>现在的 reasoning 模型把这个问题变得更严重了。推理的时候想得太多。 Reinforcement Learning from Verifiable Rewards (RLVR) 是不是导致轻松愉快随便讲个笑话变得更痛苦严肃？</p>
<p>当然还有最老生常谈的LLM幻觉问题。猜成语我想了个冷门的「投杼逾墙」，AI懵逼。btw 这个成语也是 也是卢格杜努姆的奥古斯丁 这个up主之前某一期爆的典。</p>
<p>然后又看到 <a href="https://mp.weixin.qq.com/s/k147AyWj01W-V7IpkV0g2A">Steve Yegge 的访谈</a>。的确现在 agent 生产会导致人和人的差距越来越大。我在想LLM似乎就很适合编程这种有规律可循，答案又很确定，很多写法都是 there should be one– and preferably only one –obvious way to do it，太适合 LLM 了。</p>
</article>

<div class="comments">
  <h2>Comments</h2>
  <script type="text/javascript" defer src="https://c.est.im/req4cmt.js"></script>
</div>    </main>


  </body>

</html>